{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Richly Activated Graph Convolutional Network on HRI dataset\n",
        "\n",
        "We define a custom dataset that will be used to create training/test datasets. This will also help to create a DataLoader."
      ],
      "metadata": {
        "collapsed": false,
        "id": "LOVdxGbx8wzs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "action_class = {'A001': 'Stop', 'A002': 'Go Right', 'A003': 'Go Left', 'A004': 'Come Here', 'A005': 'Follow me',\n",
        "                'A006': 'Go Away', 'A007': 'Agree', 'A008': 'Disagree', 'A009': 'Go there', 'A010': 'Get Attention',\n",
        "                'A011': 'Be Quiet', 'A012': 'Dont Know', 'A013': 'Turn Around', 'A014': 'Take This',\n",
        "                'A015': 'Pick Up', 'A016': 'Standing Still', 'A017': 'Being Seated', 'A018': 'Walking Towards',\n",
        "                'A019': 'Walking Away', 'A020': 'Talking on Phone'}\n",
        "joint_dict = {'Nose': 0, 'LEye': 1, 'REye': 2, 'LEar': 3, 'REar': 4, 'LShoulder': 5, 'RShoulder': 6, 'LElbow': 7,\n",
        "              'RElbow': 8, 'LWrist': 9, 'RWrist': 10, 'LHip': 11, 'RHip': 12, 'LKnee': 13, 'RKnee': 14,\n",
        "              'LAnkle': 15, 'RAnkle': 16}\n",
        "\n",
        "maxC = 2\n",
        "maxT = 300\n",
        "maxV = 17\n",
        "maxM = 1"
      ],
      "metadata": {
        "id": "TC06Hli28wzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35r5TAJm9JCC",
        "outputId": "db3501f7-27ad-4609-934e-f5003c2cb166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will define the RA-GCN. This is based on the original RA-GCN implementation from:\n",
        "Song, Yi-Fan, Zhang Zhang, and Liang Wang. \"Richly activated graph convolutional network for action recognition with incomplete skeletons.\" 2019 IEEE International Conference on Image Processing (ICIP). IEEE, 2019."
      ],
      "metadata": {
        "collapsed": false,
        "id": "F88uKzCx8wzz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class NTU(Dataset):\n",
        "    def __init__(self, path, train, data_shape=(3,300,17,1), transform=None):\n",
        "\n",
        "        self.train = train\n",
        "        self.path = path\n",
        "        self.maxC, self.maxT, self.maxV, self.maxM = data_shape\n",
        "        self.transform = transform\n",
        "        self.files = []\n",
        "\n",
        "        for dirpath, dirnames, filenames in os.walk(self.path):\n",
        "            self.files.append(filenames)\n",
        "\n",
        "        self.files = self.files[1]\n",
        "        self.files = np.array(self.files).flatten()\n",
        "        if self.train == 'eval':\n",
        "            self.files = random.choices(self.files, k=len(self.files) // 10)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_name = self.files[idx].strip()\n",
        "        label = ''\n",
        "\n",
        "        data = np.zeros((self.maxC, self.maxT, self.maxV, self.maxM))\n",
        "        location = np.zeros((2, self.maxT, self.maxV, self.maxM))\n",
        "        with open(self.path + file_name[4:8] + '/' + file_name, 'r') as fr:\n",
        "            frame_num = int(fr.readline())\n",
        "            for frame in range(frame_num):\n",
        "                if frame >= self.maxT:\n",
        "                    break\n",
        "                joint_num = int(fr.readline())\n",
        "                for joint in range(joint_num):\n",
        "                    v = fr.readline().split(' ')\n",
        "                    if joint < self.maxV:\n",
        "                        label = joint_dict[v[0]]\n",
        "                        data[0,frame,joint,0] = float(v[1])\n",
        "                        data[1,frame,joint,0] = float(v[2])\n",
        "                        data[2,frame,joint,0] = float(v[3])\n",
        "                        location[0,frame,joint,0] = float(v[4])\n",
        "                        location[1,frame,joint,0] = float(v[5])\n",
        "\n",
        "        if frame_num <= self.maxT:\n",
        "            data = data[:,:self.maxT,:,:]\n",
        "        else:\n",
        "            s = frame_num // self.maxT\n",
        "            r = random.randint(0, frame_num - self.maxT * s)\n",
        "            new_data = np.zeros((self.maxC, self.maxT, self.maxV, self.maxM))\n",
        "            for i in range(self.maxT):\n",
        "                new_data[:,i,:,:] = data[:,r+s*i,:,:]\n",
        "            data = new_data\n",
        "\n",
        "        if self.transform:\n",
        "            data = self.transform(data)\n",
        "\n",
        "        data = torch.from_numpy(data).float()\n",
        "        location = torch.from_numpy(location).float()\n",
        "        label = torch.from_numpy(np.array(label)).long()\n",
        "        return data, location, label, file_name"
      ],
      "metadata": {
        "id": "RKMc4IZA8wz2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class Mask(nn.Module):\n",
        "    def __init__(self, model_stream, module):\n",
        "        super(Mask, self).__init__()\n",
        "        self.model_stream = model_stream\n",
        "        self.module = module\n",
        "\n",
        "    def forward(self, weight, feature):\n",
        "        result = []\n",
        "        for i in range(self.model_stream):\n",
        "            temp_result = self.CAM(weight[i], feature[i])\n",
        "            result.append(temp_result)\n",
        "        for i in range(1, self.model_stream):\n",
        "            for j in range(i):\n",
        "                if j == 0:\n",
        "                    mask = result[j]\n",
        "                else:\n",
        "                    mask *= result[j]\n",
        "            mask = torch.cat([mask.unsqueeze(1)] * 4, dim=1)\n",
        "            self.module.mask_stream[i].data = mask.view(-1).detach()\n",
        "\n",
        "    def CAM(self, weight, feature):\n",
        "        N, C = weight.shape\n",
        "        weight = weight.view(N, C, 1, 1, 1).expand_as(feature)\n",
        "        result = (weight * feature).sum(dim=1)\n",
        "        result = result.mean(dim=0)\n",
        "\n",
        "        T, V, M = result.shape\n",
        "        result = result.view(-1)\n",
        "        result = 1 - F.softmax(result, dim=0)\n",
        "        result = F.threshold(result, 0.1, 0)\n",
        "        result = result.view(T, V, M)\n",
        "        return result\n",
        "\n"
      ],
      "metadata": {
        "id": "ShtflMl98wz4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class RA_GCN(nn.Module):\n",
        "    def __init__(self, data_shape, num_class, A, drop_prob, gcn_kernel_size, model_stream):\n",
        "        super().__init__()\n",
        "\n",
        "        C, T, V, M = data_shape\n",
        "        self.register_buffer('A', A)\n",
        "\n",
        "        # baseline\n",
        "        self.stgcn_stream = nn.ModuleList((\n",
        "            ST_GCN(data_shape, num_class, A, drop_prob, gcn_kernel_size)\n",
        "            for _ in range(model_stream)\n",
        "        ))\n",
        "\n",
        "        # mask\n",
        "        self.mask_stream = nn.ParameterList([\n",
        "            nn.Parameter(torch.ones(T * V * M))\n",
        "            for _ in range(model_stream)\n",
        "        ])\n",
        "\n",
        "\n",
        "    def forward(self, inp):\n",
        "\n",
        "        # multi stream\n",
        "        out = 0\n",
        "        feature = []\n",
        "        for stgcn, mask in zip(self.stgcn_stream, self.mask_stream):\n",
        "            x = inp\n",
        "\n",
        "            # mask\n",
        "            N, C, T, V, M = x.shape\n",
        "            x = x.view(N, C, -1)\n",
        "            x = x * mask[None,None,:]\n",
        "            x = x.view(N, C, T, V, M)\n",
        "\n",
        "            # baseline\n",
        "            temp_out, temp_feature = stgcn(x)\n",
        "\n",
        "            # output\n",
        "            out += temp_out\n",
        "            feature.append(temp_feature)\n",
        "        return out, feature\n",
        "\n",
        "\n",
        "class ST_GCN(nn.Module):\n",
        "    def __init__(self, data_shape, num_class, A, drop_prob, gcn_kernel_size):\n",
        "        super().__init__()\n",
        "\n",
        "        C, T, V, M = data_shape\n",
        "        self.register_buffer('A', A)\n",
        "\n",
        "        # data normalization\n",
        "        self.data_bn = nn.BatchNorm1d(C * V * M)\n",
        "\n",
        "        # st-gcn networks\n",
        "        self.st_gcn_networks = nn.ModuleList((\n",
        "            st_gcn_layer(C, 64, gcn_kernel_size, 1, A, drop_prob, residual=False),\n",
        "            st_gcn_layer(64, 64, gcn_kernel_size, 1, A, drop_prob),\n",
        "            st_gcn_layer(64, 64, gcn_kernel_size, 1, A, drop_prob),\n",
        "            st_gcn_layer(64, 64, gcn_kernel_size, 1, A, drop_prob),\n",
        "            st_gcn_layer(64, 128, gcn_kernel_size, 2, A, drop_prob),\n",
        "            st_gcn_layer(128, 128, gcn_kernel_size, 1, A, drop_prob),\n",
        "            st_gcn_layer(128, 128, gcn_kernel_size, 1, A, drop_prob),\n",
        "            st_gcn_layer(128, 256, gcn_kernel_size, 2, A, drop_prob),\n",
        "            st_gcn_layer(256, 256, gcn_kernel_size, 1, A, drop_prob),\n",
        "            st_gcn_layer(256, 256, gcn_kernel_size, 1, A, drop_prob),\n",
        "        ))\n",
        "\n",
        "        # edge importance weights\n",
        "        self.edge_importance = nn.ParameterList([nn.Parameter(torch.ones(A.shape)) for _ in self.st_gcn_networks])\n",
        "\n",
        "        # fcn\n",
        "        self.fcn = nn.Conv2d(256, num_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # data normalization\n",
        "        N, C, T, V, M = x.shape\n",
        "        x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
        "        x = x.view(N, M * V * C, T)\n",
        "        x = self.data_bn(x)\n",
        "        x = x.view(N, M, V, C, T)\n",
        "        x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
        "        x = x.view(N * M, C, T, V)\n",
        "\n",
        "\n",
        "\n",
        "        # forward\n",
        "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
        "            x = gcn(x, self.A * importance)\n",
        "\n",
        "        # extract feature\n",
        "        _, c, t, v = x.shape\n",
        "        feature = x.view(N, M, c, t, v).permute(0, 2, 3, 4, 1)\n",
        "\n",
        "        # global pooling\n",
        "        x = F.avg_pool2d(x, x.shape[2:])\n",
        "        x = x.view(N, M, -1, 1, 1).mean(dim=1)\n",
        "\n",
        "        # prediction\n",
        "        x = self.fcn(x)\n",
        "        x = x.view(N, -1)\n",
        "\n",
        "        return x, feature\n",
        "\n",
        "\n",
        "class st_gcn_layer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, A, drop_prob=0, residual=True):\n",
        "        super().__init__()\n",
        "\n",
        "        assert len(kernel_size) == 2\n",
        "        assert kernel_size[0] % 2 == 1\n",
        "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
        "\n",
        "        # spatial network\n",
        "        self.gcn = SpatialGraphConv(in_channels, out_channels, kernel_size[1]+1)\n",
        "\n",
        "        # temporal network\n",
        "        self.tcn = nn.Sequential(\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(drop_prob),\n",
        "            nn.Conv2d(out_channels, out_channels, (kernel_size[0],1), (stride,1), padding),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "\n",
        "        # residual\n",
        "        if not residual:\n",
        "            self.residual = lambda x: 0\n",
        "        elif (in_channels == out_channels) and (stride == 1):\n",
        "            self.residual = lambda x: x\n",
        "        else:\n",
        "            self.residual = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(stride, 1)), nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        # output\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x, A):\n",
        "\n",
        "        # residual\n",
        "        res = self.residual(x)\n",
        "\n",
        "        # spatial gcn\n",
        "        x = self.gcn(x, A)\n",
        "\n",
        "        # temporal 1d-cnn\n",
        "        x = self.tcn(x)\n",
        "\n",
        "        # output\n",
        "        x = self.relu(x + res)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpatialGraphConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, s_kernel_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # spatial class number (distance = 0 for class 0, distance = 1 for class 1, ...)\n",
        "        self.s_kernel_size = s_kernel_size\n",
        "\n",
        "        # weights of different spatial classes\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels * s_kernel_size, kernel_size=1)\n",
        "\n",
        "    def forward(self, x, A):\n",
        "\n",
        "        # numbers in same class have same weight\n",
        "        x = self.conv(x)\n",
        "\n",
        "        # divide into different classes\n",
        "        n, kc, t, v = x.shape\n",
        "        x = x.view(n, self.s_kernel_size, kc//self.s_kernel_size, t, v)\n",
        "\n",
        "        # spatial graph convolution\n",
        "        x = torch.einsum('nkctv,kvw->nctw', (x, A[:self.s_kernel_size])).contiguous()\n",
        "        return x"
      ],
      "metadata": {
        "id": "7gOuwi5p8wz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make use of the graph structure of our input data, we define a Graph class that can be used on all datapoints."
      ],
      "metadata": {
        "collapsed": false,
        "id": "bXO3V41o8wz7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class Graph:\n",
        "    def __init__(self, max_hop=1, dilation=1):\n",
        "        self.max_hop = max_hop\n",
        "        self.dilation = dilation\n",
        "\n",
        "        # get edges\n",
        "        self.num_node, self.edge, self.center = self._get_edge()\n",
        "\n",
        "        # get adjacency matrix\n",
        "        self.hop_dis = self._get_hop_distance()\n",
        "\n",
        "        # normalization\n",
        "        self.A = self._get_adjacency()\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.A\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_edge():\n",
        "        num_node = 17\n",
        "        neighbor_1base = [(1, 2), (1, 3), (2, 4), (3, 5), (6, 1), (6, 8),\n",
        "                          (7, 1), (7, 9), (8, 10), (9, 11), (12, 6), (12, 14),\n",
        "                          (13, 7), (13, 15), (14, 16), (15, 17)]\n",
        "        self_link = [(i, i) for i in range(num_node)]\n",
        "        neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_1base]\n",
        "        edge = self_link + neighbor_link\n",
        "        center = 0\n",
        "        return num_node, edge, center\n",
        "\n",
        "    def _get_hop_distance(self):\n",
        "        A = np.zeros((self.num_node, self.num_node))\n",
        "        for i, j in self.edge:\n",
        "            A[j, i] = 1\n",
        "            A[i, j] = 1\n",
        "        hop_dis = np.zeros((self.num_node, self.num_node)) + np.inf\n",
        "        transfer_mat = [np.linalg.matrix_power(A, d) for d in range(self.max_hop + 1)]\n",
        "        arrive_mat = (np.stack(transfer_mat) > 0)\n",
        "        for d in range(self.max_hop, -1, -1):\n",
        "            hop_dis[arrive_mat[d]] = d\n",
        "        return hop_dis\n",
        "\n",
        "    def _get_adjacency(self):\n",
        "        valid_hop = range(0, self.max_hop + 1, self.dilation)\n",
        "        adjacency = np.zeros((self.num_node, self.num_node))\n",
        "        for hop in valid_hop:\n",
        "            adjacency[self.hop_dis == hop] = 1\n",
        "        normalize_adjacency = self._normalize_digraph(adjacency)\n",
        "        A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
        "        for i, hop in enumerate(valid_hop):\n",
        "            A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis == hop]\n",
        "        return A\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalize_digraph(A):\n",
        "        Dl = np.sum(A, 0)\n",
        "        num_node = A.shape[0]\n",
        "        Dn = np.zeros((num_node, num_node))\n",
        "        for i in range(num_node):\n",
        "            if Dl[i] > 0:\n",
        "                Dn[i, i] = Dl[i]**(-1)\n",
        "        AD = np.dot(A, Dn)\n",
        "        return AD\n",
        "\n"
      ],
      "metadata": {
        "id": "GsGUsmGo8wz8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "class Data_transform():\n",
        "    def __init__(self, data_transform=True):\n",
        "        self.data_transform = data_transform\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.data_transform:\n",
        "            C, T, V, M = x.shape\n",
        "            x_new = np.zeros((C*3, T, V, M))\n",
        "            x_new[:C,:,:,:] = x\n",
        "            for i in range(T-1):\n",
        "                x_new[C:(2*C),i,:,:] = x[:,i+1,:,:] - x[:,i,:,:]\n",
        "            for i in range(V):\n",
        "                x_new[(2*C):,:,i,:] = x[:,:,i,:] - x[:,:,1,:]\n",
        "            return x_new\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "\n",
        "class Occlusion_part():\n",
        "    def __init__(self, occlusion_part=[]):\n",
        "        self.occlusion_part = occlusion_part\n",
        "\n",
        "        self.parts = dict()\n",
        "        self.parts[1] = np.array([7, 9, 11])              # left arm\n",
        "        self.parts[2] = np.array([6, 8, 10])           # right arm\n",
        "        self.parts[3] = np.array([10, 11])                  # two hands\n",
        "        self.parts[4] = np.array([12, 13, 14, 15, 16, 17])  # two legs\n",
        "        self.parts[5] = np.array([0, 1, 2, 3, 4, 5])                  # head\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for part in self.occlusion_part:\n",
        "            x[:,:,self.parts[part],:] = 0\n",
        "        return x\n",
        "\n",
        "\n",
        "class Occlusion_time():\n",
        "    def __init__(self, occlusion_time=0):\n",
        "        self.occlusion_time = int(occlusion_time // 2)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if not self.occlusion_time == 0:\n",
        "            x[:,(50-self.occlusion_time):(50+self.occlusion_time),:,:] = 0\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "8H9dDlgD8wz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class Mask(nn.Module):\n",
        "    def __init__(self, model_stream, module):\n",
        "        super(Mask, self).__init__()\n",
        "        self.model_stream = model_stream\n",
        "        self.module = module\n",
        "\n",
        "    def forward(self, weight, feature):\n",
        "        result = []\n",
        "        for i in range(self.model_stream):\n",
        "            temp_result = self.CAM(weight[i], feature[i])\n",
        "            result.append(temp_result)\n",
        "        for i in range(1, self.model_stream):\n",
        "            for j in range(i):\n",
        "                if j == 0:\n",
        "                    mask = result[j]\n",
        "                else:\n",
        "                    mask *= result[j]\n",
        "            mask = torch.cat([mask.unsqueeze(1)] * 4, dim=1)\n",
        "            self.module.mask_stream[i].data = mask.view(-1).detach()\n",
        "\n",
        "    def CAM(self, weight, feature):\n",
        "        N, C = weight.shape\n",
        "        weight = weight.view(N, C, 1, 1, 1).expand_as(feature)\n",
        "        result = (weight * feature).sum(dim=1)\n",
        "        result = result.mean(dim=0)\n",
        "\n",
        "        T, V, M = result.shape\n",
        "        result = result.view(-1)\n",
        "        result = 1 - F.softmax(result, dim=0)\n",
        "        result = F.threshold(result, 0.1, 0)\n",
        "        result = result.view(T, V, M)\n",
        "        return result\n",
        "\n"
      ],
      "metadata": {
        "id": "2fvDhK2n8wz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Model FCN Weights\n",
        "def get_weights(model, model_stream, y=None):\n",
        "    W = []\n",
        "    for i in range(model_stream):\n",
        "        temp_W = model.module.stgcn_stream[i].fcn.weight\n",
        "        if y is not None:\n",
        "            temp_W = temp_W[y,:]\n",
        "        W.append(temp_W.view(temp_W.shape[0], -1))\n",
        "    return W\n",
        "\n",
        "\n",
        "# Learning Rate Adjusting\n",
        "def adjust_lr(epoch, optimizer, adjustLR):\n",
        "    # LR decay\n",
        "    if epoch in adjustLR:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] /= 10\n"
      ],
      "metadata": {
        "id": "iVmFEf9MM9M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train(epoch, epochs, model, train_loader, device, optimizer, loss_func):\n",
        "    acc, num_sample = 0, 0\n",
        "    for num, (x, _, y, _) in enumerate(train_loader):\n",
        "\n",
        "        # Using GPU\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Calculating Output\n",
        "        out, feature = model(x)\n",
        "\n",
        "        # update mask matrices\n",
        "        weight = get_weights(y)\n",
        "        mask_func(weight, feature)\n",
        "\n",
        "        # Calculating Loss\n",
        "        loss = loss_func(out, y)\n",
        "\n",
        "        # Loss Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculating Accuracies\n",
        "        pred = out.max(1, keepdim=True)[1]\n",
        "        acc += pred.eq(y.view_as(pred)).sum().item()\n",
        "        num_sample += x.shape[0]\n",
        "\n",
        "        # Print Loss\n",
        "        print('Epoch: {}/{}, Batch: {}/{}, Loss: {:.4f}'.format(epoch+1, epochs, num+1, len(self.train_loader), loss))\n",
        "\n",
        "    return acc / num_sample * 100\n"
      ],
      "metadata": {
        "id": "eWrHlemc8w0B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def eval(model, eval_loader, device):\n",
        "    with torch.no_grad():\n",
        "        acc, num_sample = 0, 0\n",
        "        for num, (x, _, y, _) in enumerate(eval_loader):\n",
        "\n",
        "            # Using GPU\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Calculating Output\n",
        "            out, _ = model(x)\n",
        "\n",
        "            # Calculating Accuracies\n",
        "            pred = out.max(1, keepdim=True)[1]\n",
        "            acc += pred.eq(y.view_as(pred)).sum().item()\n",
        "            num_sample += x.shape[0]\n",
        "\n",
        "            # Print Progress\n",
        "            print('Batch: {}/{}'.format(num+1, len(eval_loader)))\n",
        "\n",
        "    return acc / num_sample * 100"
      ],
      "metadata": {
        "id": "fpn2l48o8w0B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-203-206490f160de>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mt_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mv_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-201-fb6dd5ecbbbf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, epochs, model, train_loader, device, optimizer, loss_func)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Calculating Output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# update mask matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataParallel.forward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-196-d6d67ac01c32>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mtemp_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-196-d6d67ac01c32>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2448\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2451\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 153 elements not 51"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Data Loader Setting\n",
        "num_class = 12\n",
        "data_shape = (3, 300, 17, 1)\n",
        "transform = transforms.Compose([\n",
        "    Data_transform(True),\n",
        "    Occlusion_part([]),\n",
        "    Occlusion_time(0),\n",
        "])\n",
        "\n",
        "train_dataset = NTU('/content/drive/MyDrive/HRI_gestures/skeletons/', 'train', data_shape, transform=transform)\n",
        "eval_dataset = NTU('/content/drive/MyDrive/HRI_gestures/skeletons/', 'eval', data_shape, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                               batch_size=16, num_workers=2*len([0]),\n",
        "                               pin_memory=True, shuffle=True, drop_last=True)\n",
        "eval_loader = DataLoader(eval_dataset,\n",
        "                              batch_size=16, num_workers=2*len([0]),\n",
        "                              pin_memory=True, shuffle=False, drop_last=False)\n",
        "\n",
        "graph = Graph(max_hop=2)\n",
        "A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False).to(torch.device('cpu'))\n",
        "\n",
        "# Model\n",
        "model = RA_GCN(data_shape, num_class, A, 0.5, [5,2], 3).to(torch.device('cpu'))\n",
        "model = nn.DataParallel(model)\n",
        "\n",
        "mask_func = Mask(3, model.module)\n",
        "\n",
        "\n",
        "# Optimizer Setting\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
        "\n",
        "# Loss Function Setting\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Mask Function Setting\n",
        "mask_func = Mask(3, model.module)\n",
        "\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    t_acc = train(epoch, num_epochs, model, train_loader, torch.device('cpu'), optimizer, criterion)\n",
        "    v_acc, truth, pred = eval(model, eval_loader)\n",
        "\n",
        "    train_acc.append(t_acc)\n",
        "    val_acc.append(v_acc)\n",
        "\n",
        "    # Log training/validation loss for each epoch\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_acc[epoch]:.4f}, Validation Loss: {val_acc[epoch]:.4f}\")\n",
        "\n",
        "    print(f'============================================================================')\n"
      ],
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "Pfj1Zm128w0C",
        "outputId": "34f03803-a2b8-480b-c113-bf6f9b0b733a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "n3sIFqyG8w0D"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}