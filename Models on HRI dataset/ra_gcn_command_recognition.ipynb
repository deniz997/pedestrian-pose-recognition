{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "LOVdxGbx8wzs"
   },
   "source": [
    "# Richly Activated Graph Convolutional Network on HRI dataset\n",
    "\n",
    "We define a custom dataset that will be used to create training/test datasets. This will also help to create a DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TC06Hli28wzx",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.680053700Z",
     "start_time": "2023-08-08T17:26:27.647654100Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "action_class = {'A001': 'Stop', 'A002': 'Go Right', 'A003': 'Go Left', 'A004': 'Come Here', 'A005': 'Follow me',\n",
    "                'A006': 'Go Away', 'A007': 'Agree', 'A008': 'Disagree', 'A009': 'Go there', 'A010': 'Get Attention',\n",
    "                'A011': 'Be Quiet', 'A012': 'Dont Know', 'A013': 'Turn Around', 'A014': 'Take This',\n",
    "                'A015': 'Pick Up', 'A016': 'Standing Still', 'A017': 'Being Seated', 'A018': 'Walking Towards',\n",
    "                'A019': 'Walking Away', 'A020': 'Talking on Phone'}\n",
    "lab_to_num = {'Stop': 0, 'Go Right': 1, 'Go Left': 2, 'Come Here': 3, 'Follow me': 4, 'Go Away': 5, 'Agree': 6, 'Disagree': 7,\n",
    "              'Go there': 8, 'Get Attention': 9, 'Be Quiet': 10, 'Dont Know': 11, 'Turn Around': 12, 'Take This': 13,\n",
    "              'Pick Up': 14, 'Standing Still': 15, 'Being Seated': 16, 'Walking Towards': 17, 'Walking Away': 18,\n",
    "              'Talking on Phone': 19}\n",
    "joint_dict = {'Nose': 0, 'LEye': 1, 'REye': 2, 'LEar': 3, 'REar': 4, 'LShoulder': 5, 'RShoulder': 6, 'LElbow': 7,\n",
    "              'RElbow': 8, 'LWrist': 9, 'RWrist': 10, 'LHip': 11, 'RHip': 12, 'LKnee': 13, 'RKnee': 14,\n",
    "              'LAnkle': 15, 'RAnkle': 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35r5TAJm9JCC",
    "outputId": "bfc1f22f-2286-417c-ac12-eb89650e50ba",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.695081Z",
     "start_time": "2023-08-08T17:26:28.680053700Z"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "labels_to_learn = ['Stop', 'Standing Still', 'Follow me']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.714453Z",
     "start_time": "2023-08-08T17:26:28.696080300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "F88uKzCx8wzz"
   },
   "source": [
    "Next we will define the RA-GCN. This is based on the original RA-GCN implementation from:\n",
    "Song, Yi-Fan, Zhang Zhang, and Liang Wang. \"Richly activated graph convolutional network for action recognition with incomplete skeletons.\" 2019 IEEE International Conference on Image Processing (ICIP). IEEE, 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RKMc4IZA8wz2",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.723312Z",
     "start_time": "2023-08-08T17:26:28.717453400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class NTU(Dataset):\n",
    "    def __init__(self, path, train, train_split, data_shape, transform=None):\n",
    "\n",
    "        self.train = train\n",
    "        self.path = path\n",
    "        self.maxC, self.maxT, self.maxV, self.maxM = data_shape\n",
    "        self.transform = transform\n",
    "        self.files_in = []\n",
    "        self.files = []\n",
    "\n",
    "        for dirpath, dirnames, filenames in os.walk(self.path):\n",
    "          self.files_in.append(filenames)\n",
    "\n",
    "        self.files_in = self.files_in[1:]\n",
    "\n",
    "        # Remove all data except \"Stop\", \"Follow Me\", \"Go Right\", \"Go Left\"\n",
    "        for dic in range(len(self.files_in)):\n",
    "          for file in self.files_in[dic]:\n",
    "            lab = action_class[file[:4]]\n",
    "            if lab in labels_to_learn:\n",
    "              self.files.append(file)\n",
    "                    \n",
    "        random.shuffle(self.files)\n",
    "\n",
    "        if self.train == 'train':\n",
    "          self.files = self.files[:int(len(self.files) * train_split)]\n",
    "        elif self.train == 'eval':\n",
    "          self.files = self.files[int(len(self.files) * train_split):]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx].strip()\n",
    "\n",
    "        data = np.zeros((self.maxC, self.maxT, self.maxV, self.maxM))\n",
    "        location = np.zeros((2, self.maxT, self.maxV, self.maxM))\n",
    "        with open(self.path + file_name[4:8] + '/' + file_name, 'r') as fr:\n",
    "            frame_num = int(fr.readline())\n",
    "            label = labels_to_learn.index(action_class[file_name[:4]])\n",
    "            for frame in range(frame_num):\n",
    "                if frame >= self.maxT:\n",
    "                    break\n",
    "                joint_num = int(fr.readline())\n",
    "                for joint in range(joint_num):\n",
    "                    v = fr.readline().split(' ')\n",
    "                    if joint < self.maxV:\n",
    "                        data[0,frame,joint,0] = float(v[1])\n",
    "                        data[1,frame,joint,0] = float(v[2])\n",
    "                        # [2,frame,joint,0] = float(v[3])\n",
    "                        location[0,frame,joint,0] = float(v[4])\n",
    "                        location[1,frame,joint,0] = float(v[5])\n",
    "\n",
    "        if frame_num <= self.maxT:\n",
    "            data = data[:,:self.maxT,:,:]\n",
    "        else:\n",
    "            s = frame_num // self.maxT\n",
    "            r = random.randint(0, frame_num - self.maxT * s)\n",
    "            new_data = np.zeros((self.maxC, self.maxT, self.maxV, self.maxM))\n",
    "            for i in range(self.maxT):\n",
    "                new_data[:,i,:,:] = data[:,r+s*i,:,:]\n",
    "            data = new_data\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        data = torch.from_numpy(data).float()\n",
    "        location = torch.from_numpy(location).float()\n",
    "        label = torch.from_numpy(np.array(label)).long()\n",
    "        return data, location, label, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7gOuwi5p8wz6",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.754290500Z",
     "start_time": "2023-08-08T17:26:28.726309600Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class RA_GCN(nn.Module):\n",
    "    def __init__(self, data_shape, num_class, A, drop_prob, gcn_kernel_size, model_stream):\n",
    "        super().__init__()\n",
    "\n",
    "        C, T, V, M = data_shape\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # baseline\n",
    "        self.stgcn_stream = nn.ModuleList((\n",
    "            ST_GCN(data_shape, num_class, A, drop_prob, gcn_kernel_size)\n",
    "            for _ in range(model_stream)\n",
    "        ))\n",
    "\n",
    "        # mask\n",
    "        self.mask_stream = nn.ParameterList([\n",
    "            nn.Parameter(torch.ones(T * V))\n",
    "            for _ in range(model_stream)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        # multi stream\n",
    "        out = 0\n",
    "        feature = []\n",
    "        for stgcn, mask in zip(self.stgcn_stream, self.mask_stream):\n",
    "            x = inp\n",
    "\n",
    "            # mask\n",
    "            N, C, T, V, M = x.shape\n",
    "            x = x.view(N, C, -1)\n",
    "            x = x * mask[None,None,:]\n",
    "            x = x.view(N, C, T, V, M)\n",
    "\n",
    "            # baseline\n",
    "            temp_out, temp_feature = stgcn(x)\n",
    "\n",
    "            # output\n",
    "            out += temp_out\n",
    "            feature.append(temp_feature)\n",
    "        return out, feature\n",
    "\n",
    "\n",
    "class ST_GCN(nn.Module):\n",
    "    def __init__(self, data_shape, num_class, A, drop_prob, gcn_kernel_size):\n",
    "        super().__init__()\n",
    "\n",
    "        C, T, V, M = data_shape\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # data normalization\n",
    "        self.data_bn = nn.BatchNorm1d(C * V * M)\n",
    "\n",
    "        # st-gcn networks\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            st_gcn_layer(C, 64, gcn_kernel_size, 1, A, drop_prob, residual=False),\n",
    "            st_gcn_layer(64, 64, gcn_kernel_size, 1, A, drop_prob),\n",
    "            st_gcn_layer(64, 64, gcn_kernel_size, 1, A, drop_prob),\n",
    "            st_gcn_layer(64, 64, gcn_kernel_size, 1, A, drop_prob),\n",
    "            st_gcn_layer(64, 128, gcn_kernel_size, 2, A, drop_prob),\n",
    "            st_gcn_layer(128, 128, gcn_kernel_size, 1, A, drop_prob),\n",
    "            st_gcn_layer(128, 128, gcn_kernel_size, 1, A, drop_prob),\n",
    "            st_gcn_layer(128, 256, gcn_kernel_size, 2, A, drop_prob),\n",
    "            st_gcn_layer(256, 256, gcn_kernel_size, 1, A, drop_prob),\n",
    "            st_gcn_layer(256, 256, gcn_kernel_size, 1, A, drop_prob),\n",
    "        ))\n",
    "\n",
    "        # edge importance weights\n",
    "        self.edge_importance = nn.ParameterList([nn.Parameter(torch.ones(A.shape)) for _ in self.st_gcn_networks])\n",
    "\n",
    "        # fcn\n",
    "        self.fcn = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # data normalization\n",
    "        N, C, T, V, M = x.shape\n",
    "        x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
    "        x = x.view(N, M * V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, M, V, C, T)\n",
    "        x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        x = x.view(N * M, C, T, V)\n",
    "\n",
    "        # forward\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x = gcn(x, self.A * importance)\n",
    "\n",
    "        # extract feature\n",
    "        _, c, t, v = x.shape\n",
    "        feature = x.view(N, M, c, t, v).permute(0, 2, 3, 4, 1)\n",
    "\n",
    "        # global pooling\n",
    "        x = F.avg_pool2d(x, x.shape[2:])\n",
    "        x = x.view(N, M, -1, 1, 1).mean(dim=1)\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "        x = x.view(N, -1)\n",
    "\n",
    "        return x, feature\n",
    "\n",
    "\n",
    "class st_gcn_layer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, A, drop_prob=0, residual=True):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "\n",
    "        # spatial network\n",
    "        self.gcn = SpatialGraphConv(in_channels, out_channels, kernel_size[1]+1)\n",
    "\n",
    "        # temporal network\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Conv2d(out_channels, out_channels, (kernel_size[0],1), (stride,1), padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        # residual\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(stride, 1)), nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        # output\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "\n",
    "        # residual\n",
    "        res = self.residual(x)\n",
    "\n",
    "        # spatial gcn\n",
    "        x = self.gcn(x, A)\n",
    "\n",
    "        # temporal 1d-cnn\n",
    "        x = self.tcn(x)\n",
    "\n",
    "        # output\n",
    "        x = self.relu(x + res)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpatialGraphConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, s_kernel_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # spatial class number (distance = 0 for class 0, distance = 1 for class 1, ...)\n",
    "        self.s_kernel_size = s_kernel_size\n",
    "\n",
    "        # weights of different spatial classes\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels * s_kernel_size, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "\n",
    "        # numbers in same class have same weight\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # divide into different classes\n",
    "        n, kc, t, v = x.shape\n",
    "        x = x.view(n, self.s_kernel_size, kc//self.s_kernel_size, t, v)\n",
    "\n",
    "        # spatial graph convolution\n",
    "        x = torch.einsum('nkctv,kvw->nctw', (x, A[:self.s_kernel_size])).contiguous()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "bXO3V41o8wz7"
   },
   "source": [
    "To make use of the graph structure of our input data, we define a Graph class that can be used on all datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GsGUsmGo8wz8",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.764088400Z",
     "start_time": "2023-08-08T17:26:28.748276100Z"
    }
   },
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, max_hop=1, dilation=1):\n",
    "        self.max_hop = max_hop\n",
    "        self.dilation = dilation\n",
    "\n",
    "        # get edges\n",
    "        self.num_node, self.edge, self.center = self._get_edge()\n",
    "\n",
    "        # get adjacency matrix\n",
    "        self.hop_dis = self._get_hop_distance()\n",
    "\n",
    "        # normalization\n",
    "        self.A = self._get_adjacency()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.A\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_edge():\n",
    "        num_node = 17\n",
    "        neighbor_1base = [(1, 2), (1, 3), (2, 4), (3, 5), (6, 1), (6, 8),\n",
    "                          (7, 1), (7, 9), (8, 10), (9, 11), (12, 6), (12, 14),\n",
    "                          (13, 7), (13, 15), (14, 16), (15, 17)]\n",
    "        self_link = [(i, i) for i in range(num_node)]\n",
    "        neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_1base]\n",
    "        edge = self_link + neighbor_link\n",
    "        center = 0\n",
    "        return (num_node, edge, center)\n",
    "\n",
    "    def _get_hop_distance(self):\n",
    "        A = np.zeros((self.num_node, self.num_node))\n",
    "        for i, j in self.edge:\n",
    "            A[j, i] = 1\n",
    "            A[i, j] = 1\n",
    "        hop_dis = np.zeros((self.num_node, self.num_node)) + np.inf\n",
    "        transfer_mat = [np.linalg.matrix_power(A, d) for d in range(self.max_hop + 1)]\n",
    "        arrive_mat = (np.stack(transfer_mat) > 0)\n",
    "        for d in range(self.max_hop, -1, -1):\n",
    "            hop_dis[arrive_mat[d]] = d\n",
    "        return hop_dis\n",
    "\n",
    "    def _get_adjacency(self):\n",
    "        valid_hop = range(0, self.max_hop + 1, self.dilation)\n",
    "        adjacency = np.zeros((self.num_node, self.num_node))\n",
    "        for hop in valid_hop:\n",
    "            adjacency[self.hop_dis == hop] = 1\n",
    "        normalize_adjacency = self._normalize_digraph(adjacency)\n",
    "        A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
    "        for i, hop in enumerate(valid_hop):\n",
    "            A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis == hop]\n",
    "        return A\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_digraph(A):\n",
    "        Dl = np.sum(A, 0)\n",
    "        num_node = A.shape[0]\n",
    "        Dn = np.zeros((num_node, num_node))\n",
    "        for i in range(num_node):\n",
    "            if Dl[i] > 0:\n",
    "                Dn[i, i] = Dl[i]**(-1)\n",
    "        AD = np.dot(A, Dn)\n",
    "        return AD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8H9dDlgD8wz9",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.787431200Z",
     "start_time": "2023-08-08T17:26:28.757292600Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class Data_transform():\n",
    "    def __init__(self, data_transform=True):\n",
    "        self.data_transform = data_transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.data_transform:\n",
    "            C, T, V, M = x.shape\n",
    "            x_new = np.zeros((C*3, T, V, M))\n",
    "            x_new[:C,:,:,:] = x\n",
    "            for i in range(T-1):\n",
    "                x_new[C:(2*C),i,:,:] = x[:,i+1,:,:] - x[:,i,:,:]\n",
    "            for i in range(V):\n",
    "                x_new[(2*C):,:,i,:] = x[:,:,i,:] - x[:,:,1,:]\n",
    "            return x_new\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class Occlusion_part():\n",
    "    def __init__(self, occlusion_part=[]):\n",
    "        self.occlusion_part = occlusion_part\n",
    "\n",
    "        self.parts = dict()\n",
    "        self.parts[1] = np.array([7, 9, 11])              # left arm\n",
    "        self.parts[2] = np.array([6, 8, 10])           # right arm\n",
    "        self.parts[3] = np.array([10, 11])                  # two hands\n",
    "        self.parts[4] = np.array([12, 13, 14, 15, 16, 17])  # two legs\n",
    "        self.parts[5] = np.array([0, 1, 2, 3, 4, 5])                  # head\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for part in self.occlusion_part:\n",
    "            x[:,:,self.parts[part],:] = 0\n",
    "        return x\n",
    "\n",
    "\n",
    "class Occlusion_time():\n",
    "    def __init__(self, occlusion_time=0):\n",
    "        self.occlusion_time = int(occlusion_time // 2)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not self.occlusion_time == 0:\n",
    "            x[:,(50-self.occlusion_time):(50+self.occlusion_time),:,:] = 0\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2fvDhK2n8wz_",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.793011300Z",
     "start_time": "2023-08-08T17:26:28.776614300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class Mask(nn.Module):\n",
    "    def __init__(self, model_stream, module):\n",
    "        super(Mask, self).__init__()\n",
    "        self.model_stream = model_stream\n",
    "        self.module = module\n",
    "\n",
    "        for i in range(model_stream):\n",
    "            nn.init.ones_(self.module.mask_stream[i])\n",
    "\n",
    "    def forward(self, weight, feature):\n",
    "        result = []\n",
    "        for i in range(self.model_stream):\n",
    "            temp_result = self.CAM(weight[i], feature[i])\n",
    "            result.append(temp_result)\n",
    "            print(f\"mask shape: {weight[i].shape}, feature shape: {feature[i].shape}\")\n",
    "\n",
    "        # Update mask matrices using inplace operations\n",
    "        for i in range(1, self.model_stream):\n",
    "            mask = torch.prod(torch.stack(result[:i]), dim=0)\n",
    "            mask = torch.cat([mask.unsqueeze(1)] * 4, dim=1)\n",
    "            self.module.mask_stream[i].data.copy_(mask.view(-1))\n",
    "\n",
    "    def CAM(self, weight, feature):\n",
    "        N, C = weight.shape\n",
    "        print(f'weight shape: {weight.shape}, feature shape: {feature.shape}')\n",
    "        weight = weight.view(N, C, 1, 1, 1).expand_as(feature)\n",
    "        result = (weight * feature).sum(dim=1)\n",
    "        result = result.mean(dim=0)\n",
    "\n",
    "        T, V, M = result.shape\n",
    "        result = result.view(-1)\n",
    "\n",
    "        # Ensure that the result tensor size is consistent with the mask tensor\n",
    "        if result.size(0) > self.module.mask_stream[0].data.size(0):\n",
    "            result = result[:self.module.mask_stream[0].data.size(0)]\n",
    "\n",
    "        result = 1 - F.softmax(result, dim=0)\n",
    "        result = F.threshold(result, 0.1, 0)\n",
    "        result = result.view(T, V, M)\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iVmFEf9MM9M6",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.810870Z",
     "start_time": "2023-08-08T17:26:28.789938900Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weights(model_stream, module, y=None):\n",
    "    W = []\n",
    "    for i in range(model_stream):\n",
    "        temp_W = module.stgcn_stream[i].fcn.weight\n",
    "        if y is not None:\n",
    "            temp_W = temp_W[y,:]\n",
    "        W.append(temp_W.view(temp_W.shape[0], -1))\n",
    "    return W\n",
    "\n",
    "\n",
    "# Learning Rate Adjusting\n",
    "def adjust_lr(epoch, adjustLR, optimizer):\n",
    "    # LR decay\n",
    "    if epoch in adjustLR:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] /= 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eWrHlemc8w0B",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.824145Z",
     "start_time": "2023-08-08T17:26:28.807364800Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch, epochs, model, train_loader, device, optimizer, loss_func, model_stream, mask_func):\n",
    "    acc, num_sample, total_loss = 0, 0, 0.0\n",
    "    model.train()\n",
    "    for num, (x, _, y, _) in enumerate(train_loader):\n",
    "        # Using GPU if possible\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Calculating Output\n",
    "        out, feature = model(x)\n",
    "\n",
    "        # update mask matrices\n",
    "        weight = get_weights(model_stream, model.module, y=y)\n",
    "        # TODO make the mask function work\n",
    "        # mask_func(weight, feature)\n",
    "\n",
    "        # Calculating Loss\n",
    "        loss = loss_func(out, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Loss Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculating Accuracies\n",
    "        pred = out.max(1, keepdim=True)[1]\n",
    "        acc += pred.eq(y.view_as(pred)).sum().item()\n",
    "        num_sample += x.shape[0]\n",
    "\n",
    "        # Print Loss\n",
    "        print(f'Epoch: {epoch+1}/{epochs}, Batch: {num+1}/{len(train_loader)}, Loss: {loss:.4f}')\n",
    "\n",
    "    return total_loss / len(train_loader), acc / num_sample * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fpn2l48o8w0B",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.836654Z",
     "start_time": "2023-08-08T17:26:28.823144700Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval(model, eval_loader, loss_func, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        acc, num_sample, total_loss = 0, 0, 0.0\n",
    "        for num, (x, _, y, _) in enumerate(eval_loader):\n",
    "\n",
    "            # Using GPU\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Calculating Output\n",
    "            out, _ = model(x)\n",
    "\n",
    "            # Calculating Loss\n",
    "            loss = loss_func(out, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculating Accuracies\n",
    "            pred = out.max(1, keepdim=True)[1]\n",
    "            acc += pred.eq(y.view_as(pred)).sum().item()\n",
    "            num_sample += x.shape[0]\n",
    "\n",
    "            # Print Progress\n",
    "            print(f'Batch: {num+1}/{len(eval_loader)}, Loss: {loss:.4f}')\n",
    "\n",
    "    return total_loss / len(eval_loader), acc / num_sample * 100"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ],
   "metadata": {
    "id": "Sd94He641Q_B",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:26:28.857733Z",
     "start_time": "2023-08-08T17:26:28.838653400Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Pfj1Zm128w0C",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e7cbb586-0e12-4a3c-dbb2-004bfe5d4c88",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:41:34.973065700Z",
     "start_time": "2023-08-08T17:26:28.854730800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Batch: 1/100, Loss: 1.3415\n",
      "Epoch: 1/5, Batch: 2/100, Loss: 4.9290\n",
      "Epoch: 1/5, Batch: 3/100, Loss: 1.1071\n",
      "Epoch: 1/5, Batch: 4/100, Loss: 2.4245\n",
      "Epoch: 1/5, Batch: 5/100, Loss: 1.2491\n",
      "Epoch: 1/5, Batch: 6/100, Loss: 1.6525\n",
      "Epoch: 1/5, Batch: 7/100, Loss: 1.8163\n",
      "Epoch: 1/5, Batch: 8/100, Loss: 1.2217\n",
      "Epoch: 1/5, Batch: 9/100, Loss: 0.8518\n",
      "Epoch: 1/5, Batch: 10/100, Loss: 1.2168\n",
      "Epoch: 1/5, Batch: 11/100, Loss: 0.9582\n",
      "Epoch: 1/5, Batch: 12/100, Loss: 1.6460\n",
      "Epoch: 1/5, Batch: 13/100, Loss: 1.8166\n",
      "Epoch: 1/5, Batch: 14/100, Loss: 0.9939\n",
      "Epoch: 1/5, Batch: 15/100, Loss: 1.0609\n",
      "Epoch: 1/5, Batch: 16/100, Loss: 1.0178\n",
      "Epoch: 1/5, Batch: 17/100, Loss: 1.3116\n",
      "Epoch: 1/5, Batch: 18/100, Loss: 0.7767\n",
      "Epoch: 1/5, Batch: 19/100, Loss: 1.0830\n",
      "Epoch: 1/5, Batch: 20/100, Loss: 0.9832\n",
      "Epoch: 1/5, Batch: 21/100, Loss: 1.6906\n",
      "Epoch: 1/5, Batch: 22/100, Loss: 1.2989\n",
      "Epoch: 1/5, Batch: 23/100, Loss: 1.0973\n",
      "Epoch: 1/5, Batch: 24/100, Loss: 0.9879\n",
      "Epoch: 1/5, Batch: 25/100, Loss: 0.8916\n",
      "Epoch: 1/5, Batch: 26/100, Loss: 0.8434\n",
      "Epoch: 1/5, Batch: 27/100, Loss: 1.2472\n",
      "Epoch: 1/5, Batch: 28/100, Loss: 0.5564\n",
      "Epoch: 1/5, Batch: 29/100, Loss: 0.7212\n",
      "Epoch: 1/5, Batch: 30/100, Loss: 1.1527\n",
      "Epoch: 1/5, Batch: 31/100, Loss: 0.9672\n",
      "Epoch: 1/5, Batch: 32/100, Loss: 1.0548\n",
      "Epoch: 1/5, Batch: 33/100, Loss: 1.1922\n",
      "Epoch: 1/5, Batch: 34/100, Loss: 1.0064\n",
      "Epoch: 1/5, Batch: 35/100, Loss: 1.1686\n",
      "Epoch: 1/5, Batch: 36/100, Loss: 1.3291\n",
      "Epoch: 1/5, Batch: 37/100, Loss: 1.0280\n",
      "Epoch: 1/5, Batch: 38/100, Loss: 1.1360\n",
      "Epoch: 1/5, Batch: 39/100, Loss: 0.7556\n",
      "Epoch: 1/5, Batch: 40/100, Loss: 0.6380\n",
      "Epoch: 1/5, Batch: 41/100, Loss: 1.0299\n",
      "Epoch: 1/5, Batch: 42/100, Loss: 1.0208\n",
      "Epoch: 1/5, Batch: 43/100, Loss: 0.8268\n",
      "Epoch: 1/5, Batch: 44/100, Loss: 1.3123\n",
      "Epoch: 1/5, Batch: 45/100, Loss: 0.8002\n",
      "Epoch: 1/5, Batch: 46/100, Loss: 1.3920\n",
      "Epoch: 1/5, Batch: 47/100, Loss: 0.7641\n",
      "Epoch: 1/5, Batch: 48/100, Loss: 0.9356\n",
      "Epoch: 1/5, Batch: 49/100, Loss: 0.9050\n",
      "Epoch: 1/5, Batch: 50/100, Loss: 0.6567\n",
      "Epoch: 1/5, Batch: 51/100, Loss: 0.9339\n",
      "Epoch: 1/5, Batch: 52/100, Loss: 0.8508\n",
      "Epoch: 1/5, Batch: 53/100, Loss: 1.1883\n",
      "Epoch: 1/5, Batch: 54/100, Loss: 0.7006\n",
      "Epoch: 1/5, Batch: 55/100, Loss: 0.6808\n",
      "Epoch: 1/5, Batch: 56/100, Loss: 0.7180\n",
      "Epoch: 1/5, Batch: 57/100, Loss: 0.5424\n",
      "Epoch: 1/5, Batch: 58/100, Loss: 0.6175\n",
      "Epoch: 1/5, Batch: 59/100, Loss: 0.9445\n",
      "Epoch: 1/5, Batch: 60/100, Loss: 1.1855\n",
      "Epoch: 1/5, Batch: 61/100, Loss: 0.6210\n",
      "Epoch: 1/5, Batch: 62/100, Loss: 0.9074\n",
      "Epoch: 1/5, Batch: 63/100, Loss: 0.6197\n",
      "Epoch: 1/5, Batch: 64/100, Loss: 0.8145\n",
      "Epoch: 1/5, Batch: 65/100, Loss: 0.9545\n",
      "Epoch: 1/5, Batch: 66/100, Loss: 0.5852\n",
      "Epoch: 1/5, Batch: 67/100, Loss: 0.6697\n",
      "Epoch: 1/5, Batch: 68/100, Loss: 0.5284\n",
      "Epoch: 1/5, Batch: 69/100, Loss: 0.6082\n",
      "Epoch: 1/5, Batch: 70/100, Loss: 0.7585\n",
      "Epoch: 1/5, Batch: 71/100, Loss: 1.1177\n",
      "Epoch: 1/5, Batch: 72/100, Loss: 0.6059\n",
      "Epoch: 1/5, Batch: 73/100, Loss: 0.6211\n",
      "Epoch: 1/5, Batch: 74/100, Loss: 1.1503\n",
      "Epoch: 1/5, Batch: 75/100, Loss: 0.5281\n",
      "Epoch: 1/5, Batch: 76/100, Loss: 0.5578\n",
      "Epoch: 1/5, Batch: 77/100, Loss: 0.6209\n",
      "Epoch: 1/5, Batch: 78/100, Loss: 0.6843\n",
      "Epoch: 1/5, Batch: 79/100, Loss: 0.6245\n",
      "Epoch: 1/5, Batch: 80/100, Loss: 0.5629\n",
      "Epoch: 1/5, Batch: 81/100, Loss: 0.9892\n",
      "Epoch: 1/5, Batch: 82/100, Loss: 0.3415\n",
      "Epoch: 1/5, Batch: 83/100, Loss: 0.2691\n",
      "Epoch: 1/5, Batch: 84/100, Loss: 0.3470\n",
      "Epoch: 1/5, Batch: 85/100, Loss: 0.5271\n",
      "Epoch: 1/5, Batch: 86/100, Loss: 0.2552\n",
      "Epoch: 1/5, Batch: 87/100, Loss: 0.6772\n",
      "Epoch: 1/5, Batch: 88/100, Loss: 1.1573\n",
      "Epoch: 1/5, Batch: 89/100, Loss: 0.6233\n",
      "Epoch: 1/5, Batch: 90/100, Loss: 0.4044\n",
      "Epoch: 1/5, Batch: 91/100, Loss: 0.9038\n",
      "Epoch: 1/5, Batch: 92/100, Loss: 0.5393\n",
      "Epoch: 1/5, Batch: 93/100, Loss: 0.3193\n",
      "Epoch: 1/5, Batch: 94/100, Loss: 0.3751\n",
      "Epoch: 1/5, Batch: 95/100, Loss: 0.4237\n",
      "Epoch: 1/5, Batch: 96/100, Loss: 0.4553\n",
      "Epoch: 1/5, Batch: 97/100, Loss: 0.5559\n",
      "Epoch: 1/5, Batch: 98/100, Loss: 0.6140\n",
      "Epoch: 1/5, Batch: 99/100, Loss: 0.4428\n",
      "Epoch: 1/5, Batch: 100/100, Loss: 0.9608\n",
      "Batch: 1/26, Loss: 0.2095\n",
      "Batch: 2/26, Loss: 0.8178\n",
      "Batch: 3/26, Loss: 0.4644\n",
      "Batch: 4/26, Loss: 1.1069\n",
      "Batch: 5/26, Loss: 1.2397\n",
      "Batch: 6/26, Loss: 0.7068\n",
      "Batch: 7/26, Loss: 0.6368\n",
      "Batch: 8/26, Loss: 0.4483\n",
      "Batch: 9/26, Loss: 0.2361\n",
      "Batch: 10/26, Loss: 0.2957\n",
      "Batch: 11/26, Loss: 0.6439\n",
      "Batch: 12/26, Loss: 0.2190\n",
      "Batch: 13/26, Loss: 0.6910\n",
      "Batch: 14/26, Loss: 0.7712\n",
      "Batch: 15/26, Loss: 0.3466\n",
      "Batch: 16/26, Loss: 0.4913\n",
      "Batch: 17/26, Loss: 0.2666\n",
      "Batch: 18/26, Loss: 0.2723\n",
      "Batch: 19/26, Loss: 1.7263\n",
      "Batch: 20/26, Loss: 0.5406\n",
      "Batch: 21/26, Loss: 1.3863\n",
      "Batch: 22/26, Loss: 0.5049\n",
      "Batch: 23/26, Loss: 0.2284\n",
      "Batch: 24/26, Loss: 0.8175\n",
      "Batch: 25/26, Loss: 0.5261\n",
      "Batch: 26/26, Loss: 0.3392\n",
      "Epoch [1/5], Train Accuracy: 62.1875, Validation Accuracy: 83.0846             Train Loss: 0.9355, Validation Loss: 0.6128\n",
      "============================================================================\n",
      "Epoch: 2/5, Batch: 1/100, Loss: 0.6523\n",
      "Epoch: 2/5, Batch: 2/100, Loss: 0.3616\n",
      "Epoch: 2/5, Batch: 3/100, Loss: 0.2947\n",
      "Epoch: 2/5, Batch: 4/100, Loss: 0.4275\n",
      "Epoch: 2/5, Batch: 5/100, Loss: 0.2852\n",
      "Epoch: 2/5, Batch: 6/100, Loss: 0.6814\n",
      "Epoch: 2/5, Batch: 7/100, Loss: 1.0116\n",
      "Epoch: 2/5, Batch: 8/100, Loss: 0.7137\n",
      "Epoch: 2/5, Batch: 9/100, Loss: 0.2381\n",
      "Epoch: 2/5, Batch: 10/100, Loss: 0.1514\n",
      "Epoch: 2/5, Batch: 11/100, Loss: 1.1281\n",
      "Epoch: 2/5, Batch: 12/100, Loss: 0.2394\n",
      "Epoch: 2/5, Batch: 13/100, Loss: 0.5896\n",
      "Epoch: 2/5, Batch: 14/100, Loss: 0.8871\n",
      "Epoch: 2/5, Batch: 15/100, Loss: 0.9321\n",
      "Epoch: 2/5, Batch: 16/100, Loss: 0.4304\n",
      "Epoch: 2/5, Batch: 17/100, Loss: 0.2276\n",
      "Epoch: 2/5, Batch: 18/100, Loss: 0.7911\n",
      "Epoch: 2/5, Batch: 19/100, Loss: 0.3638\n",
      "Epoch: 2/5, Batch: 20/100, Loss: 0.9234\n",
      "Epoch: 2/5, Batch: 21/100, Loss: 0.6104\n",
      "Epoch: 2/5, Batch: 22/100, Loss: 0.4990\n",
      "Epoch: 2/5, Batch: 23/100, Loss: 0.9577\n",
      "Epoch: 2/5, Batch: 24/100, Loss: 0.2652\n",
      "Epoch: 2/5, Batch: 25/100, Loss: 0.3613\n",
      "Epoch: 2/5, Batch: 26/100, Loss: 0.2264\n",
      "Epoch: 2/5, Batch: 27/100, Loss: 0.6399\n",
      "Epoch: 2/5, Batch: 28/100, Loss: 0.7064\n",
      "Epoch: 2/5, Batch: 29/100, Loss: 0.3424\n",
      "Epoch: 2/5, Batch: 30/100, Loss: 0.3770\n",
      "Epoch: 2/5, Batch: 31/100, Loss: 0.3838\n",
      "Epoch: 2/5, Batch: 32/100, Loss: 0.1891\n",
      "Epoch: 2/5, Batch: 33/100, Loss: 0.2737\n",
      "Epoch: 2/5, Batch: 34/100, Loss: 0.5787\n",
      "Epoch: 2/5, Batch: 35/100, Loss: 0.1666\n",
      "Epoch: 2/5, Batch: 36/100, Loss: 0.3736\n",
      "Epoch: 2/5, Batch: 37/100, Loss: 0.5599\n",
      "Epoch: 2/5, Batch: 38/100, Loss: 0.4501\n",
      "Epoch: 2/5, Batch: 39/100, Loss: 0.7426\n",
      "Epoch: 2/5, Batch: 40/100, Loss: 0.6410\n",
      "Epoch: 2/5, Batch: 41/100, Loss: 0.2622\n",
      "Epoch: 2/5, Batch: 42/100, Loss: 0.1286\n",
      "Epoch: 2/5, Batch: 43/100, Loss: 0.2411\n",
      "Epoch: 2/5, Batch: 44/100, Loss: 0.1891\n",
      "Epoch: 2/5, Batch: 45/100, Loss: 0.7943\n",
      "Epoch: 2/5, Batch: 46/100, Loss: 0.3438\n",
      "Epoch: 2/5, Batch: 47/100, Loss: 0.2512\n",
      "Epoch: 2/5, Batch: 48/100, Loss: 0.6404\n",
      "Epoch: 2/5, Batch: 49/100, Loss: 0.1743\n",
      "Epoch: 2/5, Batch: 50/100, Loss: 0.9661\n",
      "Epoch: 2/5, Batch: 51/100, Loss: 0.1573\n",
      "Epoch: 2/5, Batch: 52/100, Loss: 0.4957\n",
      "Epoch: 2/5, Batch: 53/100, Loss: 0.1329\n",
      "Epoch: 2/5, Batch: 54/100, Loss: 0.5855\n",
      "Epoch: 2/5, Batch: 55/100, Loss: 0.1951\n",
      "Epoch: 2/5, Batch: 56/100, Loss: 0.3964\n",
      "Epoch: 2/5, Batch: 57/100, Loss: 0.6797\n",
      "Epoch: 2/5, Batch: 58/100, Loss: 0.2557\n",
      "Epoch: 2/5, Batch: 59/100, Loss: 0.4051\n",
      "Epoch: 2/5, Batch: 60/100, Loss: 0.8180\n",
      "Epoch: 2/5, Batch: 61/100, Loss: 0.2879\n",
      "Epoch: 2/5, Batch: 62/100, Loss: 0.1863\n",
      "Epoch: 2/5, Batch: 63/100, Loss: 0.4035\n",
      "Epoch: 2/5, Batch: 64/100, Loss: 0.3075\n",
      "Epoch: 2/5, Batch: 65/100, Loss: 0.7359\n",
      "Epoch: 2/5, Batch: 66/100, Loss: 0.2214\n",
      "Epoch: 2/5, Batch: 67/100, Loss: 0.2014\n",
      "Epoch: 2/5, Batch: 68/100, Loss: 0.5853\n",
      "Epoch: 2/5, Batch: 69/100, Loss: 0.3206\n",
      "Epoch: 2/5, Batch: 70/100, Loss: 0.1506\n",
      "Epoch: 2/5, Batch: 71/100, Loss: 0.0669\n",
      "Epoch: 2/5, Batch: 72/100, Loss: 0.5440\n",
      "Epoch: 2/5, Batch: 73/100, Loss: 0.2529\n",
      "Epoch: 2/5, Batch: 74/100, Loss: 0.3141\n",
      "Epoch: 2/5, Batch: 75/100, Loss: 0.0992\n",
      "Epoch: 2/5, Batch: 76/100, Loss: 1.5695\n",
      "Epoch: 2/5, Batch: 77/100, Loss: 0.3712\n",
      "Epoch: 2/5, Batch: 78/100, Loss: 0.4660\n",
      "Epoch: 2/5, Batch: 79/100, Loss: 0.7792\n",
      "Epoch: 2/5, Batch: 80/100, Loss: 0.1854\n",
      "Epoch: 2/5, Batch: 81/100, Loss: 0.1662\n",
      "Epoch: 2/5, Batch: 82/100, Loss: 0.1874\n",
      "Epoch: 2/5, Batch: 83/100, Loss: 0.2142\n",
      "Epoch: 2/5, Batch: 84/100, Loss: 0.2007\n",
      "Epoch: 2/5, Batch: 85/100, Loss: 0.4587\n",
      "Epoch: 2/5, Batch: 86/100, Loss: 0.5247\n",
      "Epoch: 2/5, Batch: 87/100, Loss: 0.4356\n",
      "Epoch: 2/5, Batch: 88/100, Loss: 0.6125\n",
      "Epoch: 2/5, Batch: 89/100, Loss: 0.4196\n",
      "Epoch: 2/5, Batch: 90/100, Loss: 0.2554\n",
      "Epoch: 2/5, Batch: 91/100, Loss: 0.5180\n",
      "Epoch: 2/5, Batch: 92/100, Loss: 0.3466\n",
      "Epoch: 2/5, Batch: 93/100, Loss: 0.1618\n",
      "Epoch: 2/5, Batch: 94/100, Loss: 0.4156\n",
      "Epoch: 2/5, Batch: 95/100, Loss: 0.5347\n",
      "Epoch: 2/5, Batch: 96/100, Loss: 0.1656\n",
      "Epoch: 2/5, Batch: 97/100, Loss: 1.1488\n",
      "Epoch: 2/5, Batch: 98/100, Loss: 0.1878\n",
      "Epoch: 2/5, Batch: 99/100, Loss: 1.0370\n",
      "Epoch: 2/5, Batch: 100/100, Loss: 0.8974\n",
      "Batch: 1/26, Loss: 0.5446\n",
      "Batch: 2/26, Loss: 0.4240\n",
      "Batch: 3/26, Loss: 0.3775\n",
      "Batch: 4/26, Loss: 0.9929\n",
      "Batch: 5/26, Loss: 0.6769\n",
      "Batch: 6/26, Loss: 0.3844\n",
      "Batch: 7/26, Loss: 0.5512\n",
      "Batch: 8/26, Loss: 0.0374\n",
      "Batch: 9/26, Loss: 0.7328\n",
      "Batch: 10/26, Loss: 0.1873\n",
      "Batch: 11/26, Loss: 0.6767\n",
      "Batch: 12/26, Loss: 0.5431\n",
      "Batch: 13/26, Loss: 0.8181\n",
      "Batch: 14/26, Loss: 0.6212\n",
      "Batch: 15/26, Loss: 0.2401\n",
      "Batch: 16/26, Loss: 0.2601\n",
      "Batch: 17/26, Loss: 0.2678\n",
      "Batch: 18/26, Loss: 0.4866\n",
      "Batch: 19/26, Loss: 1.4302\n",
      "Batch: 20/26, Loss: 0.1215\n",
      "Batch: 21/26, Loss: 0.3140\n",
      "Batch: 22/26, Loss: 0.3855\n",
      "Batch: 23/26, Loss: 0.4729\n",
      "Batch: 24/26, Loss: 0.6015\n",
      "Batch: 25/26, Loss: 0.3740\n",
      "Batch: 26/26, Loss: 0.1220\n",
      "Epoch [2/5], Train Accuracy: 84.7500, Validation Accuracy: 82.0896             Train Loss: 0.4572, Validation Loss: 0.4863\n",
      "============================================================================\n",
      "Epoch: 3/5, Batch: 1/100, Loss: 0.1871\n",
      "Epoch: 3/5, Batch: 2/100, Loss: 0.3489\n",
      "Epoch: 3/5, Batch: 3/100, Loss: 0.3476\n",
      "Epoch: 3/5, Batch: 4/100, Loss: 0.4254\n",
      "Epoch: 3/5, Batch: 5/100, Loss: 0.2403\n",
      "Epoch: 3/5, Batch: 6/100, Loss: 0.3748\n",
      "Epoch: 3/5, Batch: 7/100, Loss: 0.2091\n",
      "Epoch: 3/5, Batch: 8/100, Loss: 0.8859\n",
      "Epoch: 3/5, Batch: 9/100, Loss: 0.7137\n",
      "Epoch: 3/5, Batch: 10/100, Loss: 0.2493\n",
      "Epoch: 3/5, Batch: 11/100, Loss: 0.4620\n",
      "Epoch: 3/5, Batch: 12/100, Loss: 0.1939\n",
      "Epoch: 3/5, Batch: 13/100, Loss: 0.5579\n",
      "Epoch: 3/5, Batch: 14/100, Loss: 0.2913\n",
      "Epoch: 3/5, Batch: 15/100, Loss: 0.1546\n",
      "Epoch: 3/5, Batch: 16/100, Loss: 0.2857\n",
      "Epoch: 3/5, Batch: 17/100, Loss: 0.1459\n",
      "Epoch: 3/5, Batch: 18/100, Loss: 0.7077\n",
      "Epoch: 3/5, Batch: 19/100, Loss: 0.2358\n",
      "Epoch: 3/5, Batch: 20/100, Loss: 0.2107\n",
      "Epoch: 3/5, Batch: 21/100, Loss: 0.4047\n",
      "Epoch: 3/5, Batch: 22/100, Loss: 0.1007\n",
      "Epoch: 3/5, Batch: 23/100, Loss: 0.5586\n",
      "Epoch: 3/5, Batch: 24/100, Loss: 0.7365\n",
      "Epoch: 3/5, Batch: 25/100, Loss: 0.3848\n",
      "Epoch: 3/5, Batch: 26/100, Loss: 0.4899\n",
      "Epoch: 3/5, Batch: 27/100, Loss: 0.5977\n",
      "Epoch: 3/5, Batch: 28/100, Loss: 0.2180\n",
      "Epoch: 3/5, Batch: 29/100, Loss: 0.4912\n",
      "Epoch: 3/5, Batch: 30/100, Loss: 0.8222\n",
      "Epoch: 3/5, Batch: 31/100, Loss: 0.7038\n",
      "Epoch: 3/5, Batch: 32/100, Loss: 0.1137\n",
      "Epoch: 3/5, Batch: 33/100, Loss: 0.5431\n",
      "Epoch: 3/5, Batch: 34/100, Loss: 0.2659\n",
      "Epoch: 3/5, Batch: 35/100, Loss: 0.1990\n",
      "Epoch: 3/5, Batch: 36/100, Loss: 0.1398\n",
      "Epoch: 3/5, Batch: 37/100, Loss: 0.5903\n",
      "Epoch: 3/5, Batch: 38/100, Loss: 0.4997\n",
      "Epoch: 3/5, Batch: 39/100, Loss: 0.2510\n",
      "Epoch: 3/5, Batch: 40/100, Loss: 0.1907\n",
      "Epoch: 3/5, Batch: 41/100, Loss: 0.5514\n",
      "Epoch: 3/5, Batch: 42/100, Loss: 0.1249\n",
      "Epoch: 3/5, Batch: 43/100, Loss: 0.1116\n",
      "Epoch: 3/5, Batch: 44/100, Loss: 0.5171\n",
      "Epoch: 3/5, Batch: 45/100, Loss: 0.2764\n",
      "Epoch: 3/5, Batch: 46/100, Loss: 0.8139\n",
      "Epoch: 3/5, Batch: 47/100, Loss: 0.2694\n",
      "Epoch: 3/5, Batch: 48/100, Loss: 0.1707\n",
      "Epoch: 3/5, Batch: 49/100, Loss: 0.3373\n",
      "Epoch: 3/5, Batch: 50/100, Loss: 0.5080\n",
      "Epoch: 3/5, Batch: 51/100, Loss: 0.8352\n",
      "Epoch: 3/5, Batch: 52/100, Loss: 0.2144\n",
      "Epoch: 3/5, Batch: 53/100, Loss: 0.1710\n",
      "Epoch: 3/5, Batch: 54/100, Loss: 0.1717\n",
      "Epoch: 3/5, Batch: 55/100, Loss: 0.2734\n",
      "Epoch: 3/5, Batch: 56/100, Loss: 0.1635\n",
      "Epoch: 3/5, Batch: 57/100, Loss: 0.5281\n",
      "Epoch: 3/5, Batch: 58/100, Loss: 0.2040\n",
      "Epoch: 3/5, Batch: 59/100, Loss: 0.2365\n",
      "Epoch: 3/5, Batch: 60/100, Loss: 0.1283\n",
      "Epoch: 3/5, Batch: 61/100, Loss: 0.6349\n",
      "Epoch: 3/5, Batch: 62/100, Loss: 0.4338\n",
      "Epoch: 3/5, Batch: 63/100, Loss: 0.2031\n",
      "Epoch: 3/5, Batch: 64/100, Loss: 0.8189\n",
      "Epoch: 3/5, Batch: 65/100, Loss: 0.0864\n",
      "Epoch: 3/5, Batch: 66/100, Loss: 0.1262\n",
      "Epoch: 3/5, Batch: 67/100, Loss: 0.8059\n",
      "Epoch: 3/5, Batch: 68/100, Loss: 0.0879\n",
      "Epoch: 3/5, Batch: 69/100, Loss: 0.6079\n",
      "Epoch: 3/5, Batch: 70/100, Loss: 0.5364\n",
      "Epoch: 3/5, Batch: 71/100, Loss: 0.1943\n",
      "Epoch: 3/5, Batch: 72/100, Loss: 0.3449\n",
      "Epoch: 3/5, Batch: 73/100, Loss: 0.2024\n",
      "Epoch: 3/5, Batch: 74/100, Loss: 0.3148\n",
      "Epoch: 3/5, Batch: 75/100, Loss: 0.2734\n",
      "Epoch: 3/5, Batch: 76/100, Loss: 0.5678\n",
      "Epoch: 3/5, Batch: 77/100, Loss: 0.2295\n",
      "Epoch: 3/5, Batch: 78/100, Loss: 0.3401\n",
      "Epoch: 3/5, Batch: 79/100, Loss: 0.8846\n",
      "Epoch: 3/5, Batch: 80/100, Loss: 0.1576\n",
      "Epoch: 3/5, Batch: 81/100, Loss: 0.2998\n",
      "Epoch: 3/5, Batch: 82/100, Loss: 0.2794\n",
      "Epoch: 3/5, Batch: 83/100, Loss: 0.5667\n",
      "Epoch: 3/5, Batch: 84/100, Loss: 1.1140\n",
      "Epoch: 3/5, Batch: 85/100, Loss: 0.2282\n",
      "Epoch: 3/5, Batch: 86/100, Loss: 0.7214\n",
      "Epoch: 3/5, Batch: 87/100, Loss: 0.2175\n",
      "Epoch: 3/5, Batch: 88/100, Loss: 0.4751\n",
      "Epoch: 3/5, Batch: 89/100, Loss: 0.2225\n",
      "Epoch: 3/5, Batch: 90/100, Loss: 0.3230\n",
      "Epoch: 3/5, Batch: 91/100, Loss: 0.0965\n",
      "Epoch: 3/5, Batch: 92/100, Loss: 0.2275\n",
      "Epoch: 3/5, Batch: 93/100, Loss: 0.1560\n",
      "Epoch: 3/5, Batch: 94/100, Loss: 0.0848\n",
      "Epoch: 3/5, Batch: 95/100, Loss: 0.0866\n",
      "Epoch: 3/5, Batch: 96/100, Loss: 0.1234\n",
      "Epoch: 3/5, Batch: 97/100, Loss: 0.3179\n",
      "Epoch: 3/5, Batch: 98/100, Loss: 0.4344\n",
      "Epoch: 3/5, Batch: 99/100, Loss: 0.1987\n",
      "Epoch: 3/5, Batch: 100/100, Loss: 0.2139\n",
      "Batch: 1/26, Loss: 0.0794\n",
      "Batch: 2/26, Loss: 0.2830\n",
      "Batch: 3/26, Loss: 0.2381\n",
      "Batch: 4/26, Loss: 0.5391\n",
      "Batch: 5/26, Loss: 0.3609\n",
      "Batch: 6/26, Loss: 0.2101\n",
      "Batch: 7/26, Loss: 0.2053\n",
      "Batch: 8/26, Loss: 0.0340\n",
      "Batch: 9/26, Loss: 0.0487\n",
      "Batch: 10/26, Loss: 0.0891\n",
      "Batch: 11/26, Loss: 0.2854\n",
      "Batch: 12/26, Loss: 0.2312\n",
      "Batch: 13/26, Loss: 0.3105\n",
      "Batch: 14/26, Loss: 0.2101\n",
      "Batch: 15/26, Loss: 0.1479\n",
      "Batch: 16/26, Loss: 0.1549\n",
      "Batch: 17/26, Loss: 0.0734\n",
      "Batch: 18/26, Loss: 0.1942\n",
      "Batch: 19/26, Loss: 0.6730\n",
      "Batch: 20/26, Loss: 0.1164\n",
      "Batch: 21/26, Loss: 0.1378\n",
      "Batch: 22/26, Loss: 0.4756\n",
      "Batch: 23/26, Loss: 0.1640\n",
      "Batch: 24/26, Loss: 0.0796\n",
      "Batch: 25/26, Loss: 0.0732\n",
      "Batch: 26/26, Loss: 0.1550\n",
      "Epoch [3/5], Train Accuracy: 88.1875, Validation Accuracy: 93.2836             Train Loss: 0.3637, Validation Loss: 0.2142\n",
      "============================================================================\n",
      "Epoch: 4/5, Batch: 1/100, Loss: 0.0569\n",
      "Epoch: 4/5, Batch: 2/100, Loss: 0.1990\n",
      "Epoch: 4/5, Batch: 3/100, Loss: 0.3570\n",
      "Epoch: 4/5, Batch: 4/100, Loss: 0.3636\n",
      "Epoch: 4/5, Batch: 5/100, Loss: 0.0571\n",
      "Epoch: 4/5, Batch: 6/100, Loss: 0.1436\n",
      "Epoch: 4/5, Batch: 7/100, Loss: 0.3669\n",
      "Epoch: 4/5, Batch: 8/100, Loss: 0.2311\n",
      "Epoch: 4/5, Batch: 9/100, Loss: 0.1027\n",
      "Epoch: 4/5, Batch: 10/100, Loss: 0.2061\n",
      "Epoch: 4/5, Batch: 11/100, Loss: 0.2726\n",
      "Epoch: 4/5, Batch: 12/100, Loss: 0.1295\n",
      "Epoch: 4/5, Batch: 13/100, Loss: 0.1670\n",
      "Epoch: 4/5, Batch: 14/100, Loss: 0.1207\n",
      "Epoch: 4/5, Batch: 15/100, Loss: 0.2006\n",
      "Epoch: 4/5, Batch: 16/100, Loss: 0.6559\n",
      "Epoch: 4/5, Batch: 17/100, Loss: 0.4281\n",
      "Epoch: 4/5, Batch: 18/100, Loss: 0.4811\n",
      "Epoch: 4/5, Batch: 19/100, Loss: 0.3291\n",
      "Epoch: 4/5, Batch: 20/100, Loss: 0.1834\n",
      "Epoch: 4/5, Batch: 21/100, Loss: 0.0748\n",
      "Epoch: 4/5, Batch: 22/100, Loss: 0.1663\n",
      "Epoch: 4/5, Batch: 23/100, Loss: 0.1858\n",
      "Epoch: 4/5, Batch: 24/100, Loss: 0.0487\n",
      "Epoch: 4/5, Batch: 25/100, Loss: 0.4822\n",
      "Epoch: 4/5, Batch: 26/100, Loss: 0.1049\n",
      "Epoch: 4/5, Batch: 27/100, Loss: 0.4762\n",
      "Epoch: 4/5, Batch: 28/100, Loss: 0.2461\n",
      "Epoch: 4/5, Batch: 29/100, Loss: 0.1256\n",
      "Epoch: 4/5, Batch: 30/100, Loss: 0.3589\n",
      "Epoch: 4/5, Batch: 31/100, Loss: 0.9072\n",
      "Epoch: 4/5, Batch: 32/100, Loss: 0.2476\n",
      "Epoch: 4/5, Batch: 33/100, Loss: 0.0363\n",
      "Epoch: 4/5, Batch: 34/100, Loss: 0.2519\n",
      "Epoch: 4/5, Batch: 35/100, Loss: 0.1885\n",
      "Epoch: 4/5, Batch: 36/100, Loss: 0.4277\n",
      "Epoch: 4/5, Batch: 37/100, Loss: 0.0914\n",
      "Epoch: 4/5, Batch: 38/100, Loss: 0.1858\n",
      "Epoch: 4/5, Batch: 39/100, Loss: 0.1203\n",
      "Epoch: 4/5, Batch: 40/100, Loss: 0.1285\n",
      "Epoch: 4/5, Batch: 41/100, Loss: 0.4200\n",
      "Epoch: 4/5, Batch: 42/100, Loss: 0.4842\n",
      "Epoch: 4/5, Batch: 43/100, Loss: 0.8618\n",
      "Epoch: 4/5, Batch: 44/100, Loss: 0.1427\n",
      "Epoch: 4/5, Batch: 45/100, Loss: 0.0917\n",
      "Epoch: 4/5, Batch: 46/100, Loss: 0.4465\n",
      "Epoch: 4/5, Batch: 47/100, Loss: 0.7262\n",
      "Epoch: 4/5, Batch: 48/100, Loss: 0.3455\n",
      "Epoch: 4/5, Batch: 49/100, Loss: 0.0877\n",
      "Epoch: 4/5, Batch: 50/100, Loss: 0.3752\n",
      "Epoch: 4/5, Batch: 51/100, Loss: 0.4200\n",
      "Epoch: 4/5, Batch: 52/100, Loss: 0.7461\n",
      "Epoch: 4/5, Batch: 53/100, Loss: 0.4189\n",
      "Epoch: 4/5, Batch: 54/100, Loss: 0.1788\n",
      "Epoch: 4/5, Batch: 55/100, Loss: 0.3009\n",
      "Epoch: 4/5, Batch: 56/100, Loss: 0.2241\n",
      "Epoch: 4/5, Batch: 57/100, Loss: 0.2913\n",
      "Epoch: 4/5, Batch: 58/100, Loss: 0.3973\n",
      "Epoch: 4/5, Batch: 59/100, Loss: 0.1430\n",
      "Epoch: 4/5, Batch: 60/100, Loss: 0.6651\n",
      "Epoch: 4/5, Batch: 61/100, Loss: 0.3366\n",
      "Epoch: 4/5, Batch: 62/100, Loss: 0.3055\n",
      "Epoch: 4/5, Batch: 63/100, Loss: 0.2660\n",
      "Epoch: 4/5, Batch: 64/100, Loss: 0.2123\n",
      "Epoch: 4/5, Batch: 65/100, Loss: 0.1281\n",
      "Epoch: 4/5, Batch: 66/100, Loss: 0.1098\n",
      "Epoch: 4/5, Batch: 67/100, Loss: 0.1063\n",
      "Epoch: 4/5, Batch: 68/100, Loss: 0.3040\n",
      "Epoch: 4/5, Batch: 69/100, Loss: 0.0759\n",
      "Epoch: 4/5, Batch: 70/100, Loss: 0.2647\n",
      "Epoch: 4/5, Batch: 71/100, Loss: 0.5613\n",
      "Epoch: 4/5, Batch: 72/100, Loss: 0.1546\n",
      "Epoch: 4/5, Batch: 73/100, Loss: 0.1643\n",
      "Epoch: 4/5, Batch: 74/100, Loss: 0.1603\n",
      "Epoch: 4/5, Batch: 75/100, Loss: 0.6750\n",
      "Epoch: 4/5, Batch: 76/100, Loss: 0.2827\n",
      "Epoch: 4/5, Batch: 77/100, Loss: 0.2862\n",
      "Epoch: 4/5, Batch: 78/100, Loss: 0.5537\n",
      "Epoch: 4/5, Batch: 79/100, Loss: 0.2514\n",
      "Epoch: 4/5, Batch: 80/100, Loss: 0.4324\n",
      "Epoch: 4/5, Batch: 81/100, Loss: 0.2489\n",
      "Epoch: 4/5, Batch: 82/100, Loss: 0.5272\n",
      "Epoch: 4/5, Batch: 83/100, Loss: 0.0646\n",
      "Epoch: 4/5, Batch: 84/100, Loss: 0.2880\n",
      "Epoch: 4/5, Batch: 85/100, Loss: 0.2523\n",
      "Epoch: 4/5, Batch: 86/100, Loss: 0.1343\n",
      "Epoch: 4/5, Batch: 87/100, Loss: 0.1582\n",
      "Epoch: 4/5, Batch: 88/100, Loss: 0.1133\n",
      "Epoch: 4/5, Batch: 89/100, Loss: 0.2130\n",
      "Epoch: 4/5, Batch: 90/100, Loss: 0.1619\n",
      "Epoch: 4/5, Batch: 91/100, Loss: 0.2109\n",
      "Epoch: 4/5, Batch: 92/100, Loss: 0.1544\n",
      "Epoch: 4/5, Batch: 93/100, Loss: 0.2650\n",
      "Epoch: 4/5, Batch: 94/100, Loss: 0.0421\n",
      "Epoch: 4/5, Batch: 95/100, Loss: 0.0375\n",
      "Epoch: 4/5, Batch: 96/100, Loss: 0.0801\n",
      "Epoch: 4/5, Batch: 97/100, Loss: 0.0511\n",
      "Epoch: 4/5, Batch: 98/100, Loss: 0.3781\n",
      "Epoch: 4/5, Batch: 99/100, Loss: 0.1229\n",
      "Epoch: 4/5, Batch: 100/100, Loss: 0.5656\n",
      "Batch: 1/26, Loss: 0.0347\n",
      "Batch: 2/26, Loss: 0.1869\n",
      "Batch: 3/26, Loss: 0.1038\n",
      "Batch: 4/26, Loss: 0.4906\n",
      "Batch: 5/26, Loss: 0.1959\n",
      "Batch: 6/26, Loss: 0.0733\n",
      "Batch: 7/26, Loss: 0.1056\n",
      "Batch: 8/26, Loss: 0.0102\n",
      "Batch: 9/26, Loss: 0.0372\n",
      "Batch: 10/26, Loss: 0.3440\n",
      "Batch: 11/26, Loss: 0.1718\n",
      "Batch: 12/26, Loss: 0.1791\n",
      "Batch: 13/26, Loss: 0.5616\n",
      "Batch: 14/26, Loss: 0.1478\n",
      "Batch: 15/26, Loss: 0.0325\n",
      "Batch: 16/26, Loss: 0.0623\n",
      "Batch: 17/26, Loss: 0.0210\n",
      "Batch: 18/26, Loss: 0.1679\n",
      "Batch: 19/26, Loss: 0.6880\n",
      "Batch: 20/26, Loss: 0.0993\n",
      "Batch: 21/26, Loss: 0.0777\n",
      "Batch: 22/26, Loss: 0.1383\n",
      "Batch: 23/26, Loss: 0.1501\n",
      "Batch: 24/26, Loss: 0.0560\n",
      "Batch: 25/26, Loss: 0.0527\n",
      "Batch: 26/26, Loss: 0.2127\n",
      "Epoch [4/5], Train Accuracy: 90.3750, Validation Accuracy: 95.2736             Train Loss: 0.2737, Validation Loss: 0.1693\n",
      "============================================================================\n",
      "Epoch: 5/5, Batch: 1/100, Loss: 0.8992\n",
      "Epoch: 5/5, Batch: 2/100, Loss: 0.2216\n",
      "Epoch: 5/5, Batch: 3/100, Loss: 0.2001\n",
      "Epoch: 5/5, Batch: 4/100, Loss: 0.3003\n",
      "Epoch: 5/5, Batch: 5/100, Loss: 0.1168\n",
      "Epoch: 5/5, Batch: 6/100, Loss: 0.1676\n",
      "Epoch: 5/5, Batch: 7/100, Loss: 0.2389\n",
      "Epoch: 5/5, Batch: 8/100, Loss: 0.1533\n",
      "Epoch: 5/5, Batch: 9/100, Loss: 0.6054\n",
      "Epoch: 5/5, Batch: 10/100, Loss: 0.2057\n",
      "Epoch: 5/5, Batch: 11/100, Loss: 0.2205\n",
      "Epoch: 5/5, Batch: 12/100, Loss: 0.1830\n",
      "Epoch: 5/5, Batch: 13/100, Loss: 0.1184\n",
      "Epoch: 5/5, Batch: 14/100, Loss: 0.1730\n",
      "Epoch: 5/5, Batch: 15/100, Loss: 0.2854\n",
      "Epoch: 5/5, Batch: 16/100, Loss: 0.2325\n",
      "Epoch: 5/5, Batch: 17/100, Loss: 0.1047\n",
      "Epoch: 5/5, Batch: 18/100, Loss: 0.0263\n",
      "Epoch: 5/5, Batch: 19/100, Loss: 0.1925\n",
      "Epoch: 5/5, Batch: 20/100, Loss: 0.0586\n",
      "Epoch: 5/5, Batch: 21/100, Loss: 0.1639\n",
      "Epoch: 5/5, Batch: 22/100, Loss: 0.0436\n",
      "Epoch: 5/5, Batch: 23/100, Loss: 0.1204\n",
      "Epoch: 5/5, Batch: 24/100, Loss: 0.1881\n",
      "Epoch: 5/5, Batch: 25/100, Loss: 1.0837\n",
      "Epoch: 5/5, Batch: 26/100, Loss: 0.3521\n",
      "Epoch: 5/5, Batch: 27/100, Loss: 0.1381\n",
      "Epoch: 5/5, Batch: 28/100, Loss: 0.3765\n",
      "Epoch: 5/5, Batch: 29/100, Loss: 0.2912\n",
      "Epoch: 5/5, Batch: 30/100, Loss: 0.6577\n",
      "Epoch: 5/5, Batch: 31/100, Loss: 0.1918\n",
      "Epoch: 5/5, Batch: 32/100, Loss: 0.0912\n",
      "Epoch: 5/5, Batch: 33/100, Loss: 0.1921\n",
      "Epoch: 5/5, Batch: 34/100, Loss: 0.1493\n",
      "Epoch: 5/5, Batch: 35/100, Loss: 0.4226\n",
      "Epoch: 5/5, Batch: 36/100, Loss: 0.0554\n",
      "Epoch: 5/5, Batch: 37/100, Loss: 0.0539\n",
      "Epoch: 5/5, Batch: 38/100, Loss: 0.3103\n",
      "Epoch: 5/5, Batch: 39/100, Loss: 0.0730\n",
      "Epoch: 5/5, Batch: 40/100, Loss: 0.4798\n",
      "Epoch: 5/5, Batch: 41/100, Loss: 0.0472\n",
      "Epoch: 5/5, Batch: 42/100, Loss: 0.5568\n",
      "Epoch: 5/5, Batch: 43/100, Loss: 0.1982\n",
      "Epoch: 5/5, Batch: 44/100, Loss: 0.6200\n",
      "Epoch: 5/5, Batch: 45/100, Loss: 0.2149\n",
      "Epoch: 5/5, Batch: 46/100, Loss: 0.1981\n",
      "Epoch: 5/5, Batch: 47/100, Loss: 0.3666\n",
      "Epoch: 5/5, Batch: 48/100, Loss: 0.5198\n",
      "Epoch: 5/5, Batch: 49/100, Loss: 0.3023\n",
      "Epoch: 5/5, Batch: 50/100, Loss: 0.1188\n",
      "Epoch: 5/5, Batch: 51/100, Loss: 0.0912\n",
      "Epoch: 5/5, Batch: 52/100, Loss: 0.0666\n",
      "Epoch: 5/5, Batch: 53/100, Loss: 0.3326\n",
      "Epoch: 5/5, Batch: 54/100, Loss: 0.4930\n",
      "Epoch: 5/5, Batch: 55/100, Loss: 0.0798\n",
      "Epoch: 5/5, Batch: 56/100, Loss: 0.2099\n",
      "Epoch: 5/5, Batch: 57/100, Loss: 1.0009\n",
      "Epoch: 5/5, Batch: 58/100, Loss: 0.3897\n",
      "Epoch: 5/5, Batch: 59/100, Loss: 0.3538\n",
      "Epoch: 5/5, Batch: 60/100, Loss: 0.2868\n",
      "Epoch: 5/5, Batch: 61/100, Loss: 0.3554\n",
      "Epoch: 5/5, Batch: 62/100, Loss: 0.0999\n",
      "Epoch: 5/5, Batch: 63/100, Loss: 0.1466\n",
      "Epoch: 5/5, Batch: 64/100, Loss: 0.1011\n",
      "Epoch: 5/5, Batch: 65/100, Loss: 0.2060\n",
      "Epoch: 5/5, Batch: 66/100, Loss: 0.1006\n",
      "Epoch: 5/5, Batch: 67/100, Loss: 0.0941\n",
      "Epoch: 5/5, Batch: 68/100, Loss: 0.1023\n",
      "Epoch: 5/5, Batch: 69/100, Loss: 0.2570\n",
      "Epoch: 5/5, Batch: 70/100, Loss: 0.2297\n",
      "Epoch: 5/5, Batch: 71/100, Loss: 0.1619\n",
      "Epoch: 5/5, Batch: 72/100, Loss: 0.4342\n",
      "Epoch: 5/5, Batch: 73/100, Loss: 0.3553\n",
      "Epoch: 5/5, Batch: 74/100, Loss: 0.2558\n",
      "Epoch: 5/5, Batch: 75/100, Loss: 0.2790\n",
      "Epoch: 5/5, Batch: 76/100, Loss: 0.0503\n",
      "Epoch: 5/5, Batch: 77/100, Loss: 0.0965\n",
      "Epoch: 5/5, Batch: 78/100, Loss: 0.0722\n",
      "Epoch: 5/5, Batch: 79/100, Loss: 0.5263\n",
      "Epoch: 5/5, Batch: 80/100, Loss: 0.5413\n",
      "Epoch: 5/5, Batch: 81/100, Loss: 0.1169\n",
      "Epoch: 5/5, Batch: 82/100, Loss: 0.1460\n",
      "Epoch: 5/5, Batch: 83/100, Loss: 0.1203\n",
      "Epoch: 5/5, Batch: 84/100, Loss: 0.2649\n",
      "Epoch: 5/5, Batch: 85/100, Loss: 0.3843\n",
      "Epoch: 5/5, Batch: 86/100, Loss: 0.3638\n",
      "Epoch: 5/5, Batch: 87/100, Loss: 0.0364\n",
      "Epoch: 5/5, Batch: 88/100, Loss: 0.3950\n",
      "Epoch: 5/5, Batch: 89/100, Loss: 0.3405\n",
      "Epoch: 5/5, Batch: 90/100, Loss: 0.4008\n",
      "Epoch: 5/5, Batch: 91/100, Loss: 0.2643\n",
      "Epoch: 5/5, Batch: 92/100, Loss: 0.4083\n",
      "Epoch: 5/5, Batch: 93/100, Loss: 0.1332\n",
      "Epoch: 5/5, Batch: 94/100, Loss: 0.0614\n",
      "Epoch: 5/5, Batch: 95/100, Loss: 0.6763\n",
      "Epoch: 5/5, Batch: 96/100, Loss: 0.0897\n",
      "Epoch: 5/5, Batch: 97/100, Loss: 0.0486\n",
      "Epoch: 5/5, Batch: 98/100, Loss: 0.0229\n",
      "Epoch: 5/5, Batch: 99/100, Loss: 0.1688\n",
      "Epoch: 5/5, Batch: 100/100, Loss: 0.3401\n",
      "Batch: 1/26, Loss: 0.1612\n",
      "Batch: 2/26, Loss: 0.5052\n",
      "Batch: 3/26, Loss: 0.1586\n",
      "Batch: 4/26, Loss: 1.2610\n",
      "Batch: 5/26, Loss: 0.2682\n",
      "Batch: 6/26, Loss: 0.1175\n",
      "Batch: 7/26, Loss: 0.2967\n",
      "Batch: 8/26, Loss: 0.4136\n",
      "Batch: 9/26, Loss: 0.0353\n",
      "Batch: 10/26, Loss: 1.0059\n",
      "Batch: 11/26, Loss: 0.1759\n",
      "Batch: 12/26, Loss: 0.7884\n",
      "Batch: 13/26, Loss: 0.1709\n",
      "Batch: 14/26, Loss: 0.0595\n",
      "Batch: 15/26, Loss: 0.0629\n",
      "Batch: 16/26, Loss: 0.0764\n",
      "Batch: 17/26, Loss: 0.1473\n",
      "Batch: 18/26, Loss: 0.1403\n",
      "Batch: 19/26, Loss: 0.7774\n",
      "Batch: 20/26, Loss: 0.6290\n",
      "Batch: 21/26, Loss: 0.4649\n",
      "Batch: 22/26, Loss: 0.2769\n",
      "Batch: 23/26, Loss: 0.3202\n",
      "Batch: 24/26, Loss: 0.2514\n",
      "Batch: 25/26, Loss: 0.0330\n",
      "Batch: 26/26, Loss: 0.6627\n",
      "Epoch [5/5], Train Accuracy: 91.3125, Validation Accuracy: 89.8010             Train Loss: 0.2583, Validation Loss: 0.3562\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data_transform = True\n",
    "\n",
    "# Data Loader Setting\n",
    "num_class = len(labels_to_learn)\n",
    "data_shape = (2, 90, 17, 1)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "    Data_transform(data_transform=data_transform),\n",
    "    Occlusion_part([]),\n",
    "    Occlusion_time(0),\n",
    "])\n",
    "\n",
    "train_dataset = NTU('../data/HRI_gestures/skeletons/', 'train', 0.8, data_shape, transform=transform)\n",
    "eval_dataset = NTU('../data/HRI_gestures/skeletons/', 'eval', 0.8, data_shape, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                               batch_size=16, #num_workers=2*len([0]),\n",
    "                               pin_memory=True, shuffle=True, drop_last=True)\n",
    "eval_loader = DataLoader(eval_dataset,\n",
    "                              batch_size=16, #num_workers=2*len([0]),\n",
    "                              pin_memory=True, shuffle=False, drop_last=False)\n",
    "\n",
    "graph = Graph(max_hop=2)\n",
    "A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False).to(DEVICE)\n",
    "\n",
    "model_stream = 3\n",
    "\n",
    "if data_transform:\n",
    "  data_shape = (6, 90, 17, 1)\n",
    "\n",
    "# Model\n",
    "model = RA_GCN(data_shape, num_class, A, 0.5, [5,2], model_stream).to(DEVICE)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "# Optimizer Setting\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Loss Function Setting\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "mask_func = Mask(model_stream, model.module)\n",
    "\n",
    "train_acc, train_loss = [], []\n",
    "val_acc, val_loss = [], []\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "early_stopper = EarlyStopper(patience=3, min_delta=1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # adjust_lr(epoch, [10,30], optimizer)\n",
    "    t_loss, t_acc = train(epoch, num_epochs, model, train_loader, DEVICE, optimizer, criterion, model_stream, mask_func)\n",
    "    v_loss, v_acc = eval(model, eval_loader, criterion, DEVICE)\n",
    "\n",
    "    train_acc.append(t_acc)\n",
    "    val_acc.append(v_acc)\n",
    "    train_loss.append(t_loss)\n",
    "    val_loss.append(v_loss)\n",
    "\n",
    "    # Log training/validation loss for each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_acc[epoch]:.4f}, Validation Accuracy: {val_acc[epoch]:.4f} \\\n",
    "            Train Loss: {train_loss[epoch]:.4f}, Validation Loss: {val_loss[epoch]:.4f}\")\n",
    "\n",
    "    if early_stopper.early_stop(val_loss[epoch]):\n",
    "        print('Stopping early to prevent overfitting and no more improvements!')\n",
    "        break\n",
    "\n",
    "    print(f'============================================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Save Model\n",
    "PATH = \"2_coord_Stop_StandingStill_FollowMe.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ],
   "metadata": {
    "id": "prjyv2_O8pwU",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:41:35.004200900Z",
     "start_time": "2023-08-08T17:41:34.975162500Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "eval_model = RA_GCN((6, 90, 17, 1), num_class, A, 0.5, [5,2], model_stream).to(DEVICE)\n",
    "eval_model = nn.DataParallel(eval_model)\n",
    "eval_model.load_state_dict(torch.load(PATH))\n",
    "eval_model.eval()"
   ],
   "metadata": {
    "id": "Qx10aW0imVVZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2ba7e73c-284c-4d8e-ac20-e4665a9c6381",
    "ExecuteTime": {
     "end_time": "2023-08-08T17:41:35.066838600Z",
     "start_time": "2023-08-08T17:41:35.004138500Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "DataParallel(\n  (module): RA_GCN(\n    (stgcn_stream): ModuleList(\n      (0-2): 3 x ST_GCN(\n        (data_bn): BatchNorm1d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (st_gcn_networks): ModuleList(\n          (0): st_gcn_layer(\n            (gcn): SpatialGraphConv(\n              (conv): Conv2d(6, 192, kernel_size=(1, 1), stride=(1, 1))\n            )\n            (tcn): Sequential(\n              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU()\n              (2): Dropout(p=0.5, inplace=False)\n              (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (relu): ReLU(inplace=True)\n          )\n          (1-3): 3 x st_gcn_layer(\n            (gcn): SpatialGraphConv(\n              (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n            )\n            (tcn): Sequential(\n              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU()\n              (2): Dropout(p=0.5, inplace=False)\n              (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (relu): ReLU(inplace=True)\n          )\n          (4): st_gcn_layer(\n            (gcn): SpatialGraphConv(\n              (conv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n            )\n            (tcn): Sequential(\n              (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU()\n              (2): Dropout(p=0.5, inplace=False)\n              (3): Conv2d(128, 128, kernel_size=(5, 1), stride=(2, 1), padding=(2, 0))\n              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (residual): Sequential(\n              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 1))\n              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (relu): ReLU(inplace=True)\n          )\n          (5-6): 2 x st_gcn_layer(\n            (gcn): SpatialGraphConv(\n              (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n            )\n            (tcn): Sequential(\n              (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU()\n              (2): Dropout(p=0.5, inplace=False)\n              (3): Conv2d(128, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (relu): ReLU(inplace=True)\n          )\n          (7): st_gcn_layer(\n            (gcn): SpatialGraphConv(\n              (conv): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1))\n            )\n            (tcn): Sequential(\n              (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU()\n              (2): Dropout(p=0.5, inplace=False)\n              (3): Conv2d(256, 256, kernel_size=(5, 1), stride=(2, 1), padding=(2, 0))\n              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (residual): Sequential(\n              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 1))\n              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (relu): ReLU(inplace=True)\n          )\n          (8-9): 2 x st_gcn_layer(\n            (gcn): SpatialGraphConv(\n              (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n            )\n            (tcn): Sequential(\n              (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU()\n              (2): Dropout(p=0.5, inplace=False)\n              (3): Conv2d(256, 256, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (relu): ReLU(inplace=True)\n          )\n        )\n        (edge_importance): ParameterList(\n            (0): Parameter containing: [torch.float32 of size 3x17x17]\n            (1): Parameter containing: [torch.float32 of size 3x17x17]\n            (2): Parameter containing: [torch.float32 of size 3x17x17]\n            (3): Parameter containing: [torch.float32 of size 3x17x17]\n            (4): Parameter containing: [torch.float32 of size 3x17x17]\n            (5): Parameter containing: [torch.float32 of size 3x17x17]\n            (6): Parameter containing: [torch.float32 of size 3x17x17]\n            (7): Parameter containing: [torch.float32 of size 3x17x17]\n            (8): Parameter containing: [torch.float32 of size 3x17x17]\n            (9): Parameter containing: [torch.float32 of size 3x17x17]\n        )\n        (fcn): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n    (mask_stream): ParameterList(\n        (0): Parameter containing: [torch.float32 of size 1530]\n        (1): Parameter containing: [torch.float32 of size 1530]\n        (2): Parameter containing: [torch.float32 of size 1530]\n    )\n  )\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_data = np.load(\"../data/hri_keypoints_robert.npy\", allow_pickle=True)\n",
    "labels = np.load(\"../data/hri_labels_robert.npy\")\n",
    "num = 12\n",
    "\n",
    "val_dataset = NTU('/content/drive/MyDrive/HRI_gestures/skeletons/', 'train', 0.8, (2, 90, 17, 1), transform=transform)\n",
    "\n",
    "for example in range(len(labels)):\n",
    "  if example == 12:\n",
    "    continue\n",
    "  x = np.zeros((2, 90, 17, 1))\n",
    "  for frame in range(len(input_data[example])):\n",
    "    for i in range(17):\n",
    "      x[0, frame, i, 0] = input_data[example][frame][i][0]\n",
    "      x[1, frame, i, 0] = input_data[example][frame][i][1]\n",
    "  x = transform(x)\n",
    "  x = torch.from_numpy(x).float()\n",
    "  x = x[None,:,:,:,:]\n",
    "  x = x.to(DEVICE)\n",
    "  out, _ = eval_model(x)\n",
    "  pred = out.max(1, keepdim=True)[1]\n",
    "  print(f'output: {pred}, output label: {labels_to_learn[pred]}')\n",
    "  print(f'label: {labels[example]}')"
   ],
   "metadata": {
    "id": "5ZPh99mXoStR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "10195076-fff8-4fea-80c9-157171656113",
    "ExecuteTime": {
     "end_time": "2023-08-08T18:05:06.988365100Z",
     "start_time": "2023-08-08T18:05:05.674103800Z"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Come Here\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Follow Me\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Follow Me\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Follow Me\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Follow Me\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Get Attention\n",
      "output: tensor([[0]]), output label: Stop\n",
      "label: Get Attention\n",
      "output: tensor([[0]]), output label: Stop\n",
      "label: Get Attention\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Go Left\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Go Left\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Go Right\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Go Right\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Standing Still\n",
      "output: tensor([[1]]), output label: Standing Still\n",
      "label: Standing Still\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Stop\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Stop\n",
      "output: tensor([[0]]), output label: Stop\n",
      "label: Stop\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Stop\n",
      "output: tensor([[2]]), output label: Follow me\n",
      "label: Stop\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x700 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for num, (x, _, y, _) in enumerate(eval_loader):\n",
    "\n",
    "    # Using GPU\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "\n",
    "    # Calculating Output\n",
    "    output, _ = model(x)\n",
    "    \n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "    \n",
    "    labels = y.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in labels_to_learn],\n",
    "                     columns = [i for i in labels_to_learn])\n",
    "plt.figure(figsize = (12,7))\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "s = sn.heatmap(df_cm, annot=True)\n",
    "s.set_xlabel('True Label', fontsize=20)\n",
    "s.set_ylabel('Predicted Label', fontsize=20)\n",
    "plt.savefig('output.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T18:12:21.646884400Z",
     "start_time": "2023-08-08T18:12:06.090082800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[687, 684, 631]\n",
      "[549, 546, 505]\n",
      "[138, 138, 126]\n"
     ]
    }
   ],
   "source": [
    "num_classes = [0, 0, 0]\n",
    "num_training = [0, 0, 0]\n",
    "num_eval = [0, 0, 0]\n",
    "\n",
    "for _, _, label, _ in train_loader:\n",
    "    for idx in label:\n",
    "        num_classes[idx] += 1\n",
    "        num_training[idx] += 1\n",
    "for _, _, label, _ in eval_loader:\n",
    "    for idx in label:\n",
    "        num_classes[idx] += 1\n",
    "        num_eval[idx] += 1\n",
    "    \n",
    "print(num_classes)\n",
    "print(num_training)\n",
    "print(num_eval)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T18:03:45.006297100Z",
     "start_time": "2023-08-08T18:03:42.047632600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
